{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "4wTjvNe4XPcy",
        "yYzm8AotHbRa"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvKFLWPZ1SdA",
        "outputId": "ca6b9486-5f56-4042-f30f-09e930cfd787"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/drive/MyDrive/iqa/ChallengeDB_release.zip -d /content/dataset"
      ],
      "metadata": {
        "id": "ed5ErN0Gx0FY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "084cbd6a-fa16-4b71-8359-af3058f64903"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace /content/dataset/ChallengeDB_release/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "wGgXEJCWAhXa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_data = pd.read_csv('/content/drive/MyDrive/iqa/mos.csv')\n",
        "labels_data = labels_data.values\n",
        "labels_data = labels_data[0]\n",
        "labels_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOIZ2kYfApKJ",
        "outputId": "0fc98f6b-1626-4d1b-8c16-d9ce2198d30b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1169,)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/dataset/ChallengeDB_release/Images'"
      ],
      "metadata": {
        "id": "4mzkXMXbV2BF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resnet50"
      ],
      "metadata": {
        "id": "N06Pln8qWaPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow.keras.models as models\n",
        "\"\"\"ResNet, ResNetV2, and ResNeXt models for Keras.\n",
        "\n",
        "# Reference papers\n",
        "\n",
        "- [Deep Residual Learning for Image Recognition]\n",
        "  (https://arxiv.org/abs/1512.03385) (CVPR 2016 Best Paper Award)\n",
        "- [Identity Mappings in Deep Residual Networks]\n",
        "  (https://arxiv.org/abs/1603.05027) (ECCV 2016)\n",
        "- [Aggregated Residual Transformations for Deep Neural Networks]\n",
        "  (https://arxiv.org/abs/1611.05431) (CVPR 2017)\n",
        "\n",
        "# Reference implementations\n",
        "\n",
        "- [TensorNets]\n",
        "  (https://github.com/taehoonlee/tensornets/blob/master/tensornets/resnets.py)\n",
        "- [Caffe ResNet]\n",
        "  (https://github.com/KaimingHe/deep-residual-networks/tree/master/prototxt)\n",
        "- [Torch ResNetV2]\n",
        "  (https://github.com/facebook/fb.resnet.torch/blob/master/models/preresnet.lua)\n",
        "- [Torch ResNeXt]\n",
        "  (https://github.com/facebookresearch/ResNeXt/blob/master/models/resnext.lua)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def block1(x, filters, kernel_size=3, stride=1,\n",
        "           conv_shortcut=True, name=None):\n",
        "    \"\"\"A residual block.\n",
        "\n",
        "    # Arguments\n",
        "        x: input tensor.\n",
        "        filters: integer, filters of the bottleneck layer.\n",
        "        kernel_size: default 3, kernel size of the bottleneck layer.\n",
        "        stride: default 1, stride of the first layer.\n",
        "        conv_shortcut: default True, use convolution shortcut if True,\n",
        "            otherwise identity shortcut.\n",
        "        name: string, block label.\n",
        "\n",
        "    # Returns\n",
        "        Output tensor for the residual block.\n",
        "    \"\"\"\n",
        "    bn_axis = 3\n",
        "\n",
        "    if conv_shortcut is True:\n",
        "        shortcut = layers.Conv2D(4 * filters, 1, strides=stride,\n",
        "                                 name=name + '_0_conv')(x)\n",
        "        shortcut = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n",
        "                                             name=name + '_0_bn')(shortcut)\n",
        "    else:\n",
        "        shortcut = x\n",
        "\n",
        "    x = layers.Conv2D(filters, 1, strides=stride, name=name + '_1_conv')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n",
        "                                  name=name + '_1_bn')(x)\n",
        "    x = layers.Activation('relu', name=name + '_1_relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters, kernel_size, padding='SAME',\n",
        "                      name=name + '_2_conv')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n",
        "                                  name=name + '_2_bn')(x)\n",
        "    x = layers.Activation('relu', name=name + '_2_relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(4 * filters, 1, name=name + '_3_conv')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n",
        "                                  name=name + '_3_bn')(x)\n",
        "\n",
        "    x = layers.Add(name=name + '_add')([shortcut, x])\n",
        "    x = layers.Activation('relu', name=name + '_out')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def stack1(x, filters, blocks, stride1=2, name=None):\n",
        "    \"\"\"A set of stacked residual blocks.\n",
        "\n",
        "    # Arguments\n",
        "        x: input tensor.\n",
        "        filters: integer, filters of the bottleneck layer in a block.\n",
        "        blocks: integer, blocks in the stacked blocks.\n",
        "        stride1: default 2, stride of the first layer in the first block.\n",
        "        name: string, stack label.\n",
        "\n",
        "    # Returns\n",
        "        Output tensor for the stacked blocks.\n",
        "    \"\"\"\n",
        "    x = block1(x, filters, stride=stride1, name=name + '_block1')\n",
        "    for i in range(2, blocks + 1):\n",
        "        x = block1(x, filters, conv_shortcut=False, name=name + '_block' + str(i))\n",
        "    return x\n",
        "\n",
        "\n",
        "def ResNet50(inputs,\n",
        "             preact=False,\n",
        "             use_bias=True,\n",
        "             model_name='resnet50',\n",
        "             include_top=False,\n",
        "             pooling='avg',\n",
        "             classes=1000,\n",
        "             return_feature_maps=True,\n",
        "             return_last_map=False):\n",
        "    \"\"\"Instantiates the ResNet, ResNetV2, and ResNeXt architecture.\n",
        "\n",
        "    Optionally loads weights pre-trained on ImageNet.\n",
        "    Note that the data format convention used by the model is\n",
        "    the one specified in your Keras config at `~/.keras/keras.json`.\n",
        "\n",
        "    # Arguments\n",
        "        stack_fn: a function that returns output tensor for the\n",
        "            stacked residual blocks.\n",
        "        preact: whether to use pre-activation or not\n",
        "            (True for ResNetV2, False for ResNet and ResNeXt).\n",
        "        use_bias: whether to use biases for convolutional layers or not\n",
        "            (True for ResNet and ResNetV2, False for ResNeXt).\n",
        "        model_name: string, model name.\n",
        "        include_top: whether to include the fully-connected\n",
        "            layer at the top of the network.\n",
        "        weights: one of `None` (random initialization),\n",
        "              'imagenet' (pre-training on ImageNet),\n",
        "              or the path to the weights file to be loaded.\n",
        "        input_tensor: optional Keras tensor\n",
        "            (i.e. output of `layers.Input()`)\n",
        "            to use as image input for the model.\n",
        "        input_shape: optional shape tuple, only to be specified\n",
        "            if `include_top` is False (otherwise the input shape\n",
        "            has to be `(224, 224, 3)` (with `channels_last` data format)\n",
        "            or `(3, 224, 224)` (with `channels_first` data format).\n",
        "            It should have exactly 3 inputs channels.\n",
        "        pooling: optional pooling mode for feature extraction\n",
        "            when `include_top` is `False`.\n",
        "            - `None` means that the output of the model will be\n",
        "                the 4D tensor output of the\n",
        "                last convolutional layer.\n",
        "            - `avg` means that global average pooling\n",
        "                will be applied to the output of the\n",
        "                last convolutional layer, and thus\n",
        "                the output of the model will be a 2D tensor.\n",
        "            - `max` means that global max pooling will\n",
        "                be applied.\n",
        "        classes: optional number of classes to classify images\n",
        "            into, only to be specified if `include_top` is True, and\n",
        "            if no `weights` argument is specified.\n",
        "\n",
        "    # Returns\n",
        "        A Keras model instance.\n",
        "\n",
        "    # Raises\n",
        "        ValueError: in case of invalid argument for `weights`,\n",
        "            or invalid input shape.\n",
        "    \"\"\"\n",
        "    # global backend, layers, models, keras_utils\n",
        "    # backend, layers, models, keras_utils = get_submodules_from_kwargs(kwargs)\n",
        "\n",
        "    # Determine proper input shape\n",
        "    bn_axis = 3\n",
        "\n",
        "    x = layers.ZeroPadding2D(padding=((3, 3), (3, 3)), name='conv1_pad')(inputs)\n",
        "    x = layers.Conv2D(64, 7, strides=2, use_bias=use_bias, name='conv1_conv')(x)\n",
        "\n",
        "    if preact is False:\n",
        "        x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n",
        "                                      name='conv1_bn')(x)\n",
        "        x = layers.Activation('relu', name='conv1_relu')(x)\n",
        "\n",
        "    x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name='pool1_pad')(x)\n",
        "    x = layers.MaxPooling2D(3, strides=2, name='pool1_pool')(x)\n",
        "\n",
        "    outputs = []\n",
        "    x = stack1(x, 64, 3, stride1=1, name='conv2')\n",
        "    outputs.append(x)\n",
        "\n",
        "    x = stack1(x, 128, 4, name='conv3')\n",
        "    outputs.append(x)\n",
        "\n",
        "    x = stack1(x, 256, 6, name='conv4')\n",
        "    outputs.append(x)\n",
        "\n",
        "    x = stack1(x, 512, 3, name='conv5')\n",
        "    outputs.append(x)\n",
        "    # x = stack_fn(x)\n",
        "\n",
        "    if return_last_map:\n",
        "        # x_shape = x.get_shape()\n",
        "        # s_shape = x_shape[1]*x_shape[2]\n",
        "        # x = tf.reshape(x, [tf.shape(x)[0], x_shape[1] * x_shape[2], x_shape[-1]])\n",
        "        # x = tf.reshape(x, [tf.shape(x)[0], tf.shape(x)[1] * tf.shape(x)[2], tf.shape(x)[-1]])\n",
        "        model = models.Model(inputs, x, name='last_map')\n",
        "        return model\n",
        "\n",
        "    if return_feature_maps:\n",
        "        model = models.Model(inputs, outputs, name=model_name)\n",
        "        return model\n",
        "\n",
        "    if preact is True:\n",
        "        x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n",
        "                                      name='post_bn')(x)\n",
        "        x = layers.Activation('relu', name='post_relu')(x)\n",
        "\n",
        "    if include_top:\n",
        "        x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "        x = layers.Dense(classes, activation='softmax', name='probs')(x)\n",
        "    else:\n",
        "        if pooling == 'avg':\n",
        "            x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "        elif pooling == 'max':\n",
        "            x = layers.GlobalMaxPooling2D(name='max_pool')(x)\n",
        "        x = layers.Dense(1, activation='linear', name='final_fc')(x)\n",
        "\n",
        "    # Create model.\n",
        "    model = models.Model(inputs, x, name=model_name)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     weights = r'.\\pretrained_weights\\resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "#     gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "#     tf.config.experimental.set_visible_devices(gpus[1], 'GPU')\n",
        "\n",
        "input_shape = (None, None, 3)\n",
        "inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "model = ResNet50(inputs,\n",
        "                     return_feature_maps=True)\n",
        "model.summary()\n",
        "#     if weights is not None:\n",
        "#         print('Load weights')\n",
        "#         model.load_weights(weights, by_name=True)\n",
        "    # C3, C4, C5 = model.outputs[1:]\n",
        "    # t = 0\n",
        "    # print(model.outputs)"
      ],
      "metadata": {
        "id": "SzKVSph8Wdcm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "510fe0ae-cbfb-4a06-aeb3-63883375b4a4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)        [(None, None, None, 3)]      0         []                            \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)   (None, None, None, 3)        0         ['input_6[0][0]']             \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)         (None, None, None, 64)       9472      ['conv1_pad[0][0]']           \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalizati  (None, None, None, 64)       256       ['conv1_conv[0][0]']          \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)     (None, None, None, 64)       0         ['conv1_bn[0][0]']            \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)   (None, None, None, 64)       0         ['conv1_relu[0][0]']          \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)   (None, None, None, 64)       0         ['pool1_pad[0][0]']           \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2  (None, None, None, 64)       4160      ['pool1_pool[0][0]']          \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNo  (None, None, None, 64)       256       ['conv2_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activ  (None, None, None, 64)       0         ['conv2_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2  (None, None, None, 64)       36928     ['conv2_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNo  (None, None, None, 64)       256       ['conv2_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activ  (None, None, None, 64)       0         ['conv2_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2  (None, None, None, 256)      16640     ['pool1_pool[0][0]']          \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2  (None, None, None, 256)      16640     ['conv2_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNo  (None, None, None, 256)      1024      ['conv2_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNo  (None, None, None, 256)      1024      ['conv2_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)      (None, None, None, 256)      0         ['conv2_block1_0_bn[0][0]',   \n",
            "                                                                     'conv2_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activati  (None, None, None, 256)      0         ['conv2_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2  (None, None, None, 64)       16448     ['conv2_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNo  (None, None, None, 64)       256       ['conv2_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activ  (None, None, None, 64)       0         ['conv2_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2  (None, None, None, 64)       36928     ['conv2_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNo  (None, None, None, 64)       256       ['conv2_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activ  (None, None, None, 64)       0         ['conv2_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2  (None, None, None, 256)      16640     ['conv2_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNo  (None, None, None, 256)      1024      ['conv2_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)      (None, None, None, 256)      0         ['conv2_block1_out[0][0]',    \n",
            "                                                                     'conv2_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activati  (None, None, None, 256)      0         ['conv2_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2  (None, None, None, 64)       16448     ['conv2_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNo  (None, None, None, 64)       256       ['conv2_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activ  (None, None, None, 64)       0         ['conv2_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2  (None, None, None, 64)       36928     ['conv2_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNo  (None, None, None, 64)       256       ['conv2_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activ  (None, None, None, 64)       0         ['conv2_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2  (None, None, None, 256)      16640     ['conv2_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNo  (None, None, None, 256)      1024      ['conv2_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)      (None, None, None, 256)      0         ['conv2_block2_out[0][0]',    \n",
            "                                                                     'conv2_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activati  (None, None, None, 256)      0         ['conv2_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2  (None, None, None, 128)      32896     ['conv2_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNo  (None, None, None, 128)      512       ['conv3_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activ  (None, None, None, 128)      0         ['conv3_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2  (None, None, None, 128)      147584    ['conv3_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNo  (None, None, None, 128)      512       ['conv3_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activ  (None, None, None, 128)      0         ['conv3_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2  (None, None, None, 512)      131584    ['conv2_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2  (None, None, None, 512)      66048     ['conv3_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNo  (None, None, None, 512)      2048      ['conv3_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNo  (None, None, None, 512)      2048      ['conv3_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)      (None, None, None, 512)      0         ['conv3_block1_0_bn[0][0]',   \n",
            "                                                                     'conv3_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activati  (None, None, None, 512)      0         ['conv3_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2  (None, None, None, 128)      65664     ['conv3_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNo  (None, None, None, 128)      512       ['conv3_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activ  (None, None, None, 128)      0         ['conv3_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2  (None, None, None, 128)      147584    ['conv3_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNo  (None, None, None, 128)      512       ['conv3_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activ  (None, None, None, 128)      0         ['conv3_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2  (None, None, None, 512)      66048     ['conv3_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNo  (None, None, None, 512)      2048      ['conv3_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)      (None, None, None, 512)      0         ['conv3_block1_out[0][0]',    \n",
            "                                                                     'conv3_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activati  (None, None, None, 512)      0         ['conv3_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2  (None, None, None, 128)      65664     ['conv3_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNo  (None, None, None, 128)      512       ['conv3_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activ  (None, None, None, 128)      0         ['conv3_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2  (None, None, None, 128)      147584    ['conv3_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNo  (None, None, None, 128)      512       ['conv3_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activ  (None, None, None, 128)      0         ['conv3_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2  (None, None, None, 512)      66048     ['conv3_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNo  (None, None, None, 512)      2048      ['conv3_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)      (None, None, None, 512)      0         ['conv3_block2_out[0][0]',    \n",
            "                                                                     'conv3_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activati  (None, None, None, 512)      0         ['conv3_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2  (None, None, None, 128)      65664     ['conv3_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNo  (None, None, None, 128)      512       ['conv3_block4_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activ  (None, None, None, 128)      0         ['conv3_block4_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2  (None, None, None, 128)      147584    ['conv3_block4_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNo  (None, None, None, 128)      512       ['conv3_block4_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activ  (None, None, None, 128)      0         ['conv3_block4_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2  (None, None, None, 512)      66048     ['conv3_block4_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNo  (None, None, None, 512)      2048      ['conv3_block4_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)      (None, None, None, 512)      0         ['conv3_block3_out[0][0]',    \n",
            "                                                                     'conv3_block4_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activati  (None, None, None, 512)      0         ['conv3_block4_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2  (None, None, None, 256)      131328    ['conv3_block4_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activ  (None, None, None, 256)      0         ['conv4_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2  (None, None, None, 256)      590080    ['conv4_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activ  (None, None, None, 256)      0         ['conv4_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2  (None, None, None, 1024)     525312    ['conv3_block4_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2  (None, None, None, 1024)     263168    ['conv4_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNo  (None, None, None, 1024)     4096      ['conv4_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNo  (None, None, None, 1024)     4096      ['conv4_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)      (None, None, None, 1024)     0         ['conv4_block1_0_bn[0][0]',   \n",
            "                                                                     'conv4_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activati  (None, None, None, 1024)     0         ['conv4_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2  (None, None, None, 256)      262400    ['conv4_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activ  (None, None, None, 256)      0         ['conv4_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2  (None, None, None, 256)      590080    ['conv4_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activ  (None, None, None, 256)      0         ['conv4_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2  (None, None, None, 1024)     263168    ['conv4_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNo  (None, None, None, 1024)     4096      ['conv4_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)      (None, None, None, 1024)     0         ['conv4_block1_out[0][0]',    \n",
            "                                                                     'conv4_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activati  (None, None, None, 1024)     0         ['conv4_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2  (None, None, None, 256)      262400    ['conv4_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activ  (None, None, None, 256)      0         ['conv4_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2  (None, None, None, 256)      590080    ['conv4_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activ  (None, None, None, 256)      0         ['conv4_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2  (None, None, None, 1024)     263168    ['conv4_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNo  (None, None, None, 1024)     4096      ['conv4_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)      (None, None, None, 1024)     0         ['conv4_block2_out[0][0]',    \n",
            "                                                                     'conv4_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activati  (None, None, None, 1024)     0         ['conv4_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2  (None, None, None, 256)      262400    ['conv4_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block4_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activ  (None, None, None, 256)      0         ['conv4_block4_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2  (None, None, None, 256)      590080    ['conv4_block4_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block4_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activ  (None, None, None, 256)      0         ['conv4_block4_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2  (None, None, None, 1024)     263168    ['conv4_block4_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNo  (None, None, None, 1024)     4096      ['conv4_block4_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)      (None, None, None, 1024)     0         ['conv4_block3_out[0][0]',    \n",
            "                                                                     'conv4_block4_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activati  (None, None, None, 1024)     0         ['conv4_block4_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2  (None, None, None, 256)      262400    ['conv4_block4_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block5_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activ  (None, None, None, 256)      0         ['conv4_block5_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2  (None, None, None, 256)      590080    ['conv4_block5_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block5_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activ  (None, None, None, 256)      0         ['conv4_block5_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2  (None, None, None, 1024)     263168    ['conv4_block5_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNo  (None, None, None, 1024)     4096      ['conv4_block5_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)      (None, None, None, 1024)     0         ['conv4_block4_out[0][0]',    \n",
            "                                                                     'conv4_block5_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activati  (None, None, None, 1024)     0         ['conv4_block5_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2  (None, None, None, 256)      262400    ['conv4_block5_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block6_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activ  (None, None, None, 256)      0         ['conv4_block6_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2  (None, None, None, 256)      590080    ['conv4_block6_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block6_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activ  (None, None, None, 256)      0         ['conv4_block6_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2  (None, None, None, 1024)     263168    ['conv4_block6_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNo  (None, None, None, 1024)     4096      ['conv4_block6_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)      (None, None, None, 1024)     0         ['conv4_block5_out[0][0]',    \n",
            "                                                                     'conv4_block6_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activati  (None, None, None, 1024)     0         ['conv4_block6_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2  (None, None, None, 512)      524800    ['conv4_block6_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNo  (None, None, None, 512)      2048      ['conv5_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activ  (None, None, None, 512)      0         ['conv5_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2  (None, None, None, 512)      2359808   ['conv5_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNo  (None, None, None, 512)      2048      ['conv5_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activ  (None, None, None, 512)      0         ['conv5_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2  (None, None, None, 2048)     2099200   ['conv4_block6_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2  (None, None, None, 2048)     1050624   ['conv5_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNo  (None, None, None, 2048)     8192      ['conv5_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNo  (None, None, None, 2048)     8192      ['conv5_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)      (None, None, None, 2048)     0         ['conv5_block1_0_bn[0][0]',   \n",
            "                                                                     'conv5_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activati  (None, None, None, 2048)     0         ['conv5_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2  (None, None, None, 512)      1049088   ['conv5_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNo  (None, None, None, 512)      2048      ['conv5_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activ  (None, None, None, 512)      0         ['conv5_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2  (None, None, None, 512)      2359808   ['conv5_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNo  (None, None, None, 512)      2048      ['conv5_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activ  (None, None, None, 512)      0         ['conv5_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2  (None, None, None, 2048)     1050624   ['conv5_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNo  (None, None, None, 2048)     8192      ['conv5_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)      (None, None, None, 2048)     0         ['conv5_block1_out[0][0]',    \n",
            "                                                                     'conv5_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activati  (None, None, None, 2048)     0         ['conv5_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2  (None, None, None, 512)      1049088   ['conv5_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNo  (None, None, None, 512)      2048      ['conv5_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activ  (None, None, None, 512)      0         ['conv5_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2  (None, None, None, 512)      2359808   ['conv5_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNo  (None, None, None, 512)      2048      ['conv5_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activ  (None, None, None, 512)      0         ['conv5_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2  (None, None, None, 2048)     1050624   ['conv5_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNo  (None, None, None, 2048)     8192      ['conv5_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)      (None, None, None, 2048)     0         ['conv5_block2_out[0][0]',    \n",
            "                                                                     'conv5_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activati  (None, None, None, 2048)     0         ['conv5_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23587712 (89.98 MB)\n",
            "Trainable params: 23534592 (89.78 MB)\n",
            "Non-trainable params: 53120 (207.50 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VGG16"
      ],
      "metadata": {
        "id": "4wTjvNe4XPcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "# pylint: disable=invalid-name\n",
        "\"\"\"VGG16 model for Keras.\"\"\"\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from tensorflow.python.keras import layers\n",
        "from tensorflow.python.keras.engine import training\n",
        "\n",
        "\n",
        "def VGG16(inputs, return_last_map=False):\n",
        "    \"\"\"Instantiates the VGG16 model.\n",
        "\n",
        "    By default, it loads weights pre-trained on ImageNet. Check 'weights' for\n",
        "    other options.\n",
        "\n",
        "    This model can be built both with 'channels_first' data format\n",
        "    (channels, height, width) or 'channels_last' data format\n",
        "    (height, width, channels).\n",
        "\n",
        "    The default input size for this model is 224x224.\n",
        "\n",
        "    Caution: Be sure to properly pre-process your inputs to the application.\n",
        "    Please see `applications.vgg16.preprocess_input` for an example.\n",
        "\n",
        "    Arguments:\n",
        "        include_top: whether to include the 3 fully-connected\n",
        "            layers at the top of the network.\n",
        "        weights: one of `None` (random initialization),\n",
        "              'imagenet' (pre-training on ImageNet),\n",
        "              or the path to the weights file to be loaded.\n",
        "        input_tensor: optional Keras tensor\n",
        "            (i.e. output of `layers.Input()`)\n",
        "            to use as image input for the model.\n",
        "        input_shape: optional shape tuple, only to be specified\n",
        "            if `include_top` is False (otherwise the input shape\n",
        "            has to be `(224, 224, 3)`\n",
        "            (with `channels_last` data format)\n",
        "            or `(3, 224, 224)` (with `channels_first` data format).\n",
        "            It should have exactly 3 input channels,\n",
        "            and width and height should be no smaller than 32.\n",
        "            E.g. `(200, 200, 3)` would be one valid value.\n",
        "        pooling: Optional pooling mode for feature extraction\n",
        "            when `include_top` is `False`.\n",
        "            - `None` means that the output of the model will be\n",
        "                the 4D tensor output of the\n",
        "                last convolutional block.\n",
        "            - `avg` means that global average pooling\n",
        "                will be applied to the output of the\n",
        "                last convolutional block, and thus\n",
        "                the output of the model will be a 2D tensor.\n",
        "            - `max` means that global max pooling will\n",
        "                be applied.\n",
        "        classes: optional number of classes to classify images\n",
        "            into, only to be specified if `include_top` is True, and\n",
        "            if no `weights` argument is specified.\n",
        "        classifier_activation: A `str` or callable. The activation function to use\n",
        "            on the \"top\" layer. Ignored unless `include_top=True`. Set\n",
        "            `classifier_activation=None` to return the logits of the \"top\" layer.\n",
        "\n",
        "    Returns:\n",
        "      A `keras.Model` instance.\n",
        "\n",
        "    Raises:\n",
        "      ValueError: in case of invalid argument for `weights`,\n",
        "        or invalid input shape.\n",
        "      ValueError: if `classifier_activation` is not `softmax` or `None` when\n",
        "        using a pretrained top layer.\n",
        "    \"\"\"\n",
        "\n",
        "    # Block 1\n",
        "    x = layers.Conv2D(\n",
        "        64, (3, 3), activation='relu', padding='same', name='block1_conv1')(\n",
        "        inputs)\n",
        "    x = layers.Conv2D(\n",
        "        64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
        "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
        "\n",
        "    outputs = []\n",
        "    # Block 2\n",
        "    x = layers.Conv2D(\n",
        "        128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
        "    x = layers.Conv2D(\n",
        "        128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
        "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
        "    outputs.append(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = layers.Conv2D(\n",
        "        256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
        "    x = layers.Conv2D(\n",
        "        256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
        "    x = layers.Conv2D(\n",
        "        256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
        "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
        "    outputs.append(x)\n",
        "\n",
        "    # Block 4\n",
        "    x = layers.Conv2D(\n",
        "        512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
        "    x = layers.Conv2D(\n",
        "        512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
        "    x = layers.Conv2D(\n",
        "        512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
        "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
        "    outputs.append(x)\n",
        "\n",
        "    # Block 5\n",
        "    x = layers.Conv2D(\n",
        "        512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
        "    x = layers.Conv2D(\n",
        "        512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
        "    x = layers.Conv2D(\n",
        "        512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
        "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
        "    outputs.append(x)\n",
        "\n",
        "    if return_last_map:\n",
        "        model = training.Model(inputs, x, name='vgg16')\n",
        "    else:\n",
        "        # Create model.\n",
        "        model = training.Model(inputs, outputs, name='vgg16')\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     model = VGG16(None)"
      ],
      "metadata": {
        "id": "o2sVydZ2XVVK"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer\n"
      ],
      "metadata": {
        "id": "yYzm8AotHbRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yu2xX1UhJyMK",
        "outputId": "a77a27da-7d5f-4034-f2e3-987eed188b8b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.10/dist-packages (0.22.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (23.2)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (2.13.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras.layers import (\n",
        "    Dense,\n",
        "    Dropout,\n",
        "    LayerNormalization,\n",
        "    Layer,\n",
        "    Conv2D,\n",
        "    MaxPool2D\n",
        ")\n",
        "\n",
        "\n",
        "def create_padding_mask(input):\n",
        "    \"\"\"\n",
        "    Creates mask for input to Transformer based on the average of all elements = 0\n",
        "    :param input: input sequence\n",
        "    :return: mask\n",
        "    \"\"\"\n",
        "    input = tf.pad(input, paddings=[[0, 0], [1, 0], [0, 0]], constant_values=1)\n",
        "    input = tf.cast(tf.math.equal(tf.keras.backend.mean(input, axis=-1), 0), tf.float32)\n",
        "\n",
        "    # add extra dimensions to add the padding to the attention logits.\n",
        "    return input[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
        "\n",
        "\n",
        "class MultiHeadAttention(Layer):\n",
        "    \"\"\"\n",
        "    This is the standard multi-head attention layer\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, num_heads=8):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        if d_model % num_heads != 0:\n",
        "            raise ValueError(\n",
        "                f'embedding dimension = {d_model} should be divisible by number of heads = {num_heads}'\n",
        "            )\n",
        "        self.depth = d_model // num_heads\n",
        "\n",
        "        self.wq = Dense(d_model)\n",
        "        self.wk = Dense(d_model)\n",
        "        self.wv = Dense(d_model)\n",
        "\n",
        "        self.dense = Dense(d_model)\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(\n",
        "            x, (batch_size, -1, self.num_heads, self.depth)\n",
        "        )\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def scaled_dot_product_attention(self, query, key, value, mask):\n",
        "        matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        scaled_score = matmul_qk / tf.math.sqrt(dim_key)\n",
        "        if mask is not None:\n",
        "            scaled_score += (mask * -1e9)\n",
        "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
        "        output = tf.matmul(weights, value)\n",
        "        return output, weights\n",
        "\n",
        "    def call(self, inputs, mask):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "\n",
        "        query = self.wq(inputs)\n",
        "        key = self.wk(inputs)\n",
        "        value = self.wv(inputs)\n",
        "\n",
        "        query = self.split_heads(query, batch_size)\n",
        "        key = self.split_heads(key, batch_size)\n",
        "        value = self.split_heads(value, batch_size)\n",
        "\n",
        "        attention, weights = self.scaled_dot_product_attention(query, key, value, mask)\n",
        "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
        "        concat_attention = tf.reshape(\n",
        "            attention, (batch_size, -1, self.d_model)\n",
        "        )\n",
        "        output = self.dense(concat_attention)\n",
        "        return output, weights\n",
        "\n",
        "\n",
        "class TransformerBlock(Layer):\n",
        "    \"\"\"\n",
        "    This is the standard Transformer block\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, num_heads, dff, dropout=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn = tf.keras.Sequential(\n",
        "            [Dense(dff, activation=\"relu\"),\n",
        "             Dense(d_model),]\n",
        "        )\n",
        "\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = Dropout(dropout)\n",
        "        self.dropout2 = Dropout(dropout)\n",
        "\n",
        "    def call(self, x, training, mask, vis=False):\n",
        "        attn_output, attention_weigths = self.mha(x, mask)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(x + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        out2 = self.layernorm2(out1 + ffn_output)\n",
        "        if vis:\n",
        "            return out2, attention_weigths\n",
        "        else:\n",
        "            return out2\n",
        "\n",
        "\n",
        "class TriQImageQualityTransformer(Model):\n",
        "    \"\"\"\n",
        "    Transformer for video quality assessment using the standard Transformer,\n",
        "    the maximum_position_encoding should cover the maximal clip number in the databases\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_layers,\n",
        "        d_model,\n",
        "        num_heads,\n",
        "        mlp_dim,\n",
        "        dropout=0.1,\n",
        "        n_quality_levels=5,\n",
        "        maximum_position_encoding=257,\n",
        "        vis=False\n",
        "    ):\n",
        "        super(TriQImageQualityTransformer, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # positional embedding is predefined with a sufficient length\n",
        "        self.pos_emb = self.add_weight('pos_emb', shape=(1, maximum_position_encoding, d_model))\n",
        "\n",
        "        # add video quality token\n",
        "        self.quality_emb = self.add_weight('quality_emb', shape=(1, 1, d_model))\n",
        "\n",
        "        # normal Transformer architecture\n",
        "        self.feature_proj_conv = Conv2D(d_model, (1, 1))\n",
        "        # self.feature_proj = Dense(d_model)\n",
        "\n",
        "        # self.pooling_big = MaxPool2D(pool_size=(4, 4))\n",
        "        self.pooling_small = MaxPool2D(pool_size=(2, 2))\n",
        "\n",
        "        self.dropout = Dropout(dropout)\n",
        "        self.enc_layers = [\n",
        "            TransformerBlock(d_model, num_heads, mlp_dim, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ]\n",
        "        self.vis = vis\n",
        "\n",
        "        # MLP head\n",
        "        if n_quality_levels > 1:\n",
        "            mlp_activation = 'softmax'\n",
        "        else:\n",
        "            mlp_activation = 'linear'\n",
        "        self.mlp_head = tf.keras.Sequential(\n",
        "            [\n",
        "                Dense(mlp_dim, activation=tfa.activations.gelu),\n",
        "                Dropout(dropout),\n",
        "                Dense(n_quality_levels, activation=mlp_activation),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def call(self, x, training):\n",
        "        batch_size = tf.shape(x)[0]\n",
        "\n",
        "        # spatial_size = tf.shape(x)[1] * tf.shape(x)[2]\n",
        "        mask = None\n",
        "\n",
        "        # x = tf.reshape(x, [batch_size, spatial_size, 2048])\n",
        "        # print('{}, {}'.format(batch_size, spatial_size))\n",
        "\n",
        "        # x = self.feature_proj(x)\n",
        "        x = self.feature_proj_conv(x)\n",
        "\n",
        "        if tf.shape(x)[1] >= 16:\n",
        "            x = self.pooling_small(x)\n",
        "        # elif tf.shape(x)[2] >= 24:\n",
        "        #     x = self.pooling_small(x)\n",
        "\n",
        "        spatial_size = tf.shape(x)[1] * tf.shape(x)[2]\n",
        "        x = tf.reshape(x, [batch_size, spatial_size, self.d_model])\n",
        "\n",
        "        # x = tf.reshape(x, [batch_size, 192, 2048])\n",
        "        # x = self.feature_proj(x)\n",
        "\n",
        "        quality_emb = tf.broadcast_to(self.quality_emb, [batch_size, 1, self.d_model])\n",
        "        x = tf.concat([quality_emb, x], axis=1)\n",
        "\n",
        "        # truncate the positional embedding for shorter videos\n",
        "        # print(spatial_size)\n",
        "        x = x + self.pos_emb[:, : spatial_size + 1, :]\n",
        "        # x = x + self.pos_emb\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        if self.vis:\n",
        "            attention_weights = []\n",
        "            for layer in self.enc_layers:\n",
        "                x, attention_weight = layer(x, training, mask, vis=True)\n",
        "                attention_weights.append(attention_weight)\n",
        "\n",
        "        else:\n",
        "            for layer in self.enc_layers:\n",
        "                x = layer(x, training, mask)\n",
        "\n",
        "        # First (CLS) is used for VQA\n",
        "        # return x[:, 0]\n",
        "        x = self.mlp_head(x[:, 0])\n",
        "\n",
        "        if self.vis:\n",
        "            return x, attention_weights\n",
        "        else:\n",
        "            return x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzZeiBXxHf0V",
        "outputId": "8c7eddba-d2e5-48d3-dea4-09a7feda98a7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRIQ"
      ],
      "metadata": {
        "id": "7YLBWaTLYije"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Main function to build TRIQ.\n",
        "\"\"\"\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "# from backbone.resnet50 import ResNet50\n",
        "# from backbone.vgg16 import VGG16\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def create_triq_model(n_quality_levels,\n",
        "                      input_shape=(None, None, 3),\n",
        "                      backbone='resnet50',\n",
        "                      transformer_params=(2, 32, 8, 64),\n",
        "                      maximum_position_encoding=193,\n",
        "                      vis=False):\n",
        "    \"\"\"\n",
        "    Creates the hybrid TRIQ model\n",
        "    :param n_quality_levels: number of quality levels, use 5 to predict quality distribution\n",
        "    :param input_shape: input shape\n",
        "    :param backbone: bakbone nets, supports ResNet50 and VGG16 now\n",
        "    :param transformer_params: Transformer parameters\n",
        "    :param maximum_position_encoding: the maximal number of positional embeddings\n",
        "    :param vis: flag to visualize attention weight maps\n",
        "    :return: TRIQ model\n",
        "    \"\"\"\n",
        "    inputs = Input(shape=input_shape)\n",
        "    if backbone == 'resnet50':\n",
        "        backbone_model = ResNet50(inputs,\n",
        "                                  return_feature_maps=False, return_last_map=True)\n",
        "    elif backbone == 'vgg16':\n",
        "        backbone_model = VGG16(inputs, return_last_map=True)\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    C5 = backbone_model.output\n",
        "\n",
        "    dropout_rate = 0.1\n",
        "\n",
        "    transformer = TriQImageQualityTransformer(\n",
        "        num_layers=transformer_params[0],\n",
        "        d_model=transformer_params[1],\n",
        "        num_heads=transformer_params[2],\n",
        "        mlp_dim=transformer_params[3],\n",
        "        dropout=dropout_rate,\n",
        "        n_quality_levels=n_quality_levels,\n",
        "        maximum_position_encoding=maximum_position_encoding,\n",
        "        vis=vis\n",
        "    )\n",
        "    outputs = transformer(C5)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    # model.summary()\n",
        "    return model\n",
        "\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "print(gpus)\n",
        "tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
        "# input_shape = [None, None, 3]\n",
        "    # input_shape = [768, 1024, 3]\n",
        "input_shape = [500, 500, 3]\n",
        "    # input_shape = [384, 512, 3]\n",
        "    # model = cnn_transformer(n_quality_levels=5, input_shape=input_shape, backbone='vgg16')\n",
        "model = create_triq_model(n_quality_levels=5, input_shape=input_shape, backbone='resnet50')\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IM1OnAmUFxP",
        "outputId": "5d9d72df-4482-4afc-8a61-dc54c79eabcf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_7 (InputLayer)        [(None, 500, 500, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)   (None, 506, 506, 3)          0         ['input_7[0][0]']             \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)         (None, 250, 250, 64)         9472      ['conv1_pad[0][0]']           \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalizati  (None, 250, 250, 64)         256       ['conv1_conv[0][0]']          \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)     (None, 250, 250, 64)         0         ['conv1_bn[0][0]']            \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)   (None, 252, 252, 64)         0         ['conv1_relu[0][0]']          \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)   (None, 125, 125, 64)         0         ['pool1_pad[0][0]']           \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2  (None, 125, 125, 64)         4160      ['pool1_pool[0][0]']          \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNo  (None, 125, 125, 64)         256       ['conv2_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activ  (None, 125, 125, 64)         0         ['conv2_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2  (None, 125, 125, 64)         36928     ['conv2_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNo  (None, 125, 125, 64)         256       ['conv2_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activ  (None, 125, 125, 64)         0         ['conv2_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2  (None, 125, 125, 256)        16640     ['pool1_pool[0][0]']          \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2  (None, 125, 125, 256)        16640     ['conv2_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNo  (None, 125, 125, 256)        1024      ['conv2_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNo  (None, 125, 125, 256)        1024      ['conv2_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)      (None, 125, 125, 256)        0         ['conv2_block1_0_bn[0][0]',   \n",
            "                                                                     'conv2_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activati  (None, 125, 125, 256)        0         ['conv2_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2  (None, 125, 125, 64)         16448     ['conv2_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNo  (None, 125, 125, 64)         256       ['conv2_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activ  (None, 125, 125, 64)         0         ['conv2_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2  (None, 125, 125, 64)         36928     ['conv2_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNo  (None, 125, 125, 64)         256       ['conv2_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activ  (None, 125, 125, 64)         0         ['conv2_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2  (None, 125, 125, 256)        16640     ['conv2_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNo  (None, 125, 125, 256)        1024      ['conv2_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)      (None, 125, 125, 256)        0         ['conv2_block1_out[0][0]',    \n",
            "                                                                     'conv2_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activati  (None, 125, 125, 256)        0         ['conv2_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2  (None, 125, 125, 64)         16448     ['conv2_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNo  (None, 125, 125, 64)         256       ['conv2_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activ  (None, 125, 125, 64)         0         ['conv2_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2  (None, 125, 125, 64)         36928     ['conv2_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNo  (None, 125, 125, 64)         256       ['conv2_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activ  (None, 125, 125, 64)         0         ['conv2_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2  (None, 125, 125, 256)        16640     ['conv2_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNo  (None, 125, 125, 256)        1024      ['conv2_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)      (None, 125, 125, 256)        0         ['conv2_block2_out[0][0]',    \n",
            "                                                                     'conv2_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activati  (None, 125, 125, 256)        0         ['conv2_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2  (None, 63, 63, 128)          32896     ['conv2_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNo  (None, 63, 63, 128)          512       ['conv3_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activ  (None, 63, 63, 128)          0         ['conv3_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2  (None, 63, 63, 128)          147584    ['conv3_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNo  (None, 63, 63, 128)          512       ['conv3_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activ  (None, 63, 63, 128)          0         ['conv3_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2  (None, 63, 63, 512)          131584    ['conv2_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2  (None, 63, 63, 512)          66048     ['conv3_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNo  (None, 63, 63, 512)          2048      ['conv3_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNo  (None, 63, 63, 512)          2048      ['conv3_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)      (None, 63, 63, 512)          0         ['conv3_block1_0_bn[0][0]',   \n",
            "                                                                     'conv3_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activati  (None, 63, 63, 512)          0         ['conv3_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2  (None, 63, 63, 128)          65664     ['conv3_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNo  (None, 63, 63, 128)          512       ['conv3_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activ  (None, 63, 63, 128)          0         ['conv3_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2  (None, 63, 63, 128)          147584    ['conv3_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNo  (None, 63, 63, 128)          512       ['conv3_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activ  (None, 63, 63, 128)          0         ['conv3_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2  (None, 63, 63, 512)          66048     ['conv3_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNo  (None, 63, 63, 512)          2048      ['conv3_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)      (None, 63, 63, 512)          0         ['conv3_block1_out[0][0]',    \n",
            "                                                                     'conv3_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activati  (None, 63, 63, 512)          0         ['conv3_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2  (None, 63, 63, 128)          65664     ['conv3_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNo  (None, 63, 63, 128)          512       ['conv3_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activ  (None, 63, 63, 128)          0         ['conv3_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2  (None, 63, 63, 128)          147584    ['conv3_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNo  (None, 63, 63, 128)          512       ['conv3_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activ  (None, 63, 63, 128)          0         ['conv3_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2  (None, 63, 63, 512)          66048     ['conv3_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNo  (None, 63, 63, 512)          2048      ['conv3_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)      (None, 63, 63, 512)          0         ['conv3_block2_out[0][0]',    \n",
            "                                                                     'conv3_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activati  (None, 63, 63, 512)          0         ['conv3_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2  (None, 63, 63, 128)          65664     ['conv3_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNo  (None, 63, 63, 128)          512       ['conv3_block4_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activ  (None, 63, 63, 128)          0         ['conv3_block4_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2  (None, 63, 63, 128)          147584    ['conv3_block4_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNo  (None, 63, 63, 128)          512       ['conv3_block4_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activ  (None, 63, 63, 128)          0         ['conv3_block4_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2  (None, 63, 63, 512)          66048     ['conv3_block4_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNo  (None, 63, 63, 512)          2048      ['conv3_block4_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)      (None, 63, 63, 512)          0         ['conv3_block3_out[0][0]',    \n",
            "                                                                     'conv3_block4_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activati  (None, 63, 63, 512)          0         ['conv3_block4_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2  (None, 32, 32, 256)          131328    ['conv3_block4_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNo  (None, 32, 32, 256)          1024      ['conv4_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activ  (None, 32, 32, 256)          0         ['conv4_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2  (None, 32, 32, 256)          590080    ['conv4_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNo  (None, 32, 32, 256)          1024      ['conv4_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activ  (None, 32, 32, 256)          0         ['conv4_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2  (None, 32, 32, 1024)         525312    ['conv3_block4_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2  (None, 32, 32, 1024)         263168    ['conv4_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNo  (None, 32, 32, 1024)         4096      ['conv4_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNo  (None, 32, 32, 1024)         4096      ['conv4_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)      (None, 32, 32, 1024)         0         ['conv4_block1_0_bn[0][0]',   \n",
            "                                                                     'conv4_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activati  (None, 32, 32, 1024)         0         ['conv4_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2  (None, 32, 32, 256)          262400    ['conv4_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNo  (None, 32, 32, 256)          1024      ['conv4_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activ  (None, 32, 32, 256)          0         ['conv4_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2  (None, 32, 32, 256)          590080    ['conv4_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNo  (None, 32, 32, 256)          1024      ['conv4_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activ  (None, 32, 32, 256)          0         ['conv4_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2  (None, 32, 32, 1024)         263168    ['conv4_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNo  (None, 32, 32, 1024)         4096      ['conv4_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)      (None, 32, 32, 1024)         0         ['conv4_block1_out[0][0]',    \n",
            "                                                                     'conv4_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activati  (None, 32, 32, 1024)         0         ['conv4_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2  (None, 32, 32, 256)          262400    ['conv4_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNo  (None, 32, 32, 256)          1024      ['conv4_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activ  (None, 32, 32, 256)          0         ['conv4_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2  (None, 32, 32, 256)          590080    ['conv4_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNo  (None, 32, 32, 256)          1024      ['conv4_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activ  (None, 32, 32, 256)          0         ['conv4_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2  (None, 32, 32, 1024)         263168    ['conv4_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNo  (None, 32, 32, 1024)         4096      ['conv4_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)      (None, 32, 32, 1024)         0         ['conv4_block2_out[0][0]',    \n",
            "                                                                     'conv4_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activati  (None, 32, 32, 1024)         0         ['conv4_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2  (None, 32, 32, 256)          262400    ['conv4_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNo  (None, 32, 32, 256)          1024      ['conv4_block4_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activ  (None, 32, 32, 256)          0         ['conv4_block4_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2  (None, 32, 32, 256)          590080    ['conv4_block4_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNo  (None, 32, 32, 256)          1024      ['conv4_block4_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activ  (None, 32, 32, 256)          0         ['conv4_block4_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2  (None, 32, 32, 1024)         263168    ['conv4_block4_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNo  (None, 32, 32, 1024)         4096      ['conv4_block4_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)      (None, 32, 32, 1024)         0         ['conv4_block3_out[0][0]',    \n",
            "                                                                     'conv4_block4_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activati  (None, 32, 32, 1024)         0         ['conv4_block4_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2  (None, 32, 32, 256)          262400    ['conv4_block4_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNo  (None, 32, 32, 256)          1024      ['conv4_block5_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activ  (None, 32, 32, 256)          0         ['conv4_block5_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2  (None, 32, 32, 256)          590080    ['conv4_block5_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNo  (None, 32, 32, 256)          1024      ['conv4_block5_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activ  (None, 32, 32, 256)          0         ['conv4_block5_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2  (None, 32, 32, 1024)         263168    ['conv4_block5_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNo  (None, 32, 32, 1024)         4096      ['conv4_block5_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)      (None, 32, 32, 1024)         0         ['conv4_block4_out[0][0]',    \n",
            "                                                                     'conv4_block5_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activati  (None, 32, 32, 1024)         0         ['conv4_block5_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2  (None, 32, 32, 256)          262400    ['conv4_block5_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNo  (None, 32, 32, 256)          1024      ['conv4_block6_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activ  (None, 32, 32, 256)          0         ['conv4_block6_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2  (None, 32, 32, 256)          590080    ['conv4_block6_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNo  (None, 32, 32, 256)          1024      ['conv4_block6_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activ  (None, 32, 32, 256)          0         ['conv4_block6_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2  (None, 32, 32, 1024)         263168    ['conv4_block6_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNo  (None, 32, 32, 1024)         4096      ['conv4_block6_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)      (None, 32, 32, 1024)         0         ['conv4_block5_out[0][0]',    \n",
            "                                                                     'conv4_block6_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activati  (None, 32, 32, 1024)         0         ['conv4_block6_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2  (None, 16, 16, 512)          524800    ['conv4_block6_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNo  (None, 16, 16, 512)          2048      ['conv5_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activ  (None, 16, 16, 512)          0         ['conv5_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2  (None, 16, 16, 512)          2359808   ['conv5_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNo  (None, 16, 16, 512)          2048      ['conv5_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activ  (None, 16, 16, 512)          0         ['conv5_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2  (None, 16, 16, 2048)         2099200   ['conv4_block6_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2  (None, 16, 16, 2048)         1050624   ['conv5_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNo  (None, 16, 16, 2048)         8192      ['conv5_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNo  (None, 16, 16, 2048)         8192      ['conv5_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)      (None, 16, 16, 2048)         0         ['conv5_block1_0_bn[0][0]',   \n",
            "                                                                     'conv5_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activati  (None, 16, 16, 2048)         0         ['conv5_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2  (None, 16, 16, 512)          1049088   ['conv5_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNo  (None, 16, 16, 512)          2048      ['conv5_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activ  (None, 16, 16, 512)          0         ['conv5_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2  (None, 16, 16, 512)          2359808   ['conv5_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNo  (None, 16, 16, 512)          2048      ['conv5_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activ  (None, 16, 16, 512)          0         ['conv5_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2  (None, 16, 16, 2048)         1050624   ['conv5_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNo  (None, 16, 16, 2048)         8192      ['conv5_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)      (None, 16, 16, 2048)         0         ['conv5_block1_out[0][0]',    \n",
            "                                                                     'conv5_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activati  (None, 16, 16, 2048)         0         ['conv5_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2  (None, 16, 16, 512)          1049088   ['conv5_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNo  (None, 16, 16, 512)          2048      ['conv5_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activ  (None, 16, 16, 512)          0         ['conv5_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2  (None, 16, 16, 512)          2359808   ['conv5_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNo  (None, 16, 16, 512)          2048      ['conv5_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activ  (None, 16, 16, 512)          0         ['conv5_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2  (None, 16, 16, 2048)         1050624   ['conv5_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNo  (None, 16, 16, 2048)         8192      ['conv5_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)      (None, 16, 16, 2048)         0         ['conv5_block2_out[0][0]',    \n",
            "                                                                     'conv5_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activati  (None, 16, 16, 2048)         0         ['conv5_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " tri_q_image_quality_transf  (None, 5)                    91301     ['conv5_block3_out[0][0]']    \n",
            " ormer (TriQImageQualityTra                                                                       \n",
            " nsformer)                                                                                        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23679013 (90.33 MB)\n",
            "Trainable params: 23625893 (90.13 MB)\n",
            "Non-trainable params: 53120 (207.50 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Callbacks"
      ],
      "metadata": {
        "id": "x9DG5EivFquU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import collections\n",
        "import csv\n",
        "import io\n",
        "from tensorflow.python.lib.io import file_io\n",
        "\n",
        "import numpy as np\n",
        "import six\n",
        "import datetime\n",
        "\n",
        "from tensorflow.python.util.compat import collections_abc\n",
        "from tensorflow.keras.callbacks import CSVLogger\n",
        "\n",
        "\n",
        "class MyCSVLogger(CSVLogger):\n",
        "    \"\"\"\n",
        "    This is basically a copy of CSVLogger, the only change is that 4 decimal precision is used in loggers.\n",
        "    \"\"\"\n",
        "    def __init__(self, filename, model_name=None, separator=',', append=False):\n",
        "        self.model_name = model_name\n",
        "        super(MyCSVLogger, self).__init__(filename, separator, append)\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        if self.append:\n",
        "            if file_io.file_exists(self.filename):\n",
        "                with open(self.filename, 'r' + self.file_flags) as f:\n",
        "                    self.append_header = not bool(len(f.readline()))\n",
        "            mode = 'a'\n",
        "        else:\n",
        "            mode = 'w'\n",
        "        self.csv_file = io.open(self.filename,\n",
        "                                mode + self.file_flags,\n",
        "                                **self._open_args)\n",
        "        if self.model_name:\n",
        "            self.csv_file.write('\\nModel name: {}\\n'.format(self.model_name))\n",
        "        self.csv_file.write('\\nTrain start: {}\\n'.format(datetime.datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")))\n",
        "        self.csv_file.flush()\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "\n",
        "        def handle_value(k):\n",
        "            is_zero_dim_ndarray = isinstance(k, np.ndarray) and k.ndim == 0\n",
        "            if isinstance(k, six.string_types):\n",
        "                return k\n",
        "            elif isinstance(k, collections_abc.Iterable) and not is_zero_dim_ndarray:\n",
        "                return '\"[%s]\"' % (', '.join(map(str, k)))\n",
        "            else:\n",
        "                return '{:.4f}'.format(k)\n",
        "\n",
        "        if self.keys is None:\n",
        "            self.keys = sorted(logs.keys())\n",
        "\n",
        "        if self.model.stop_training:\n",
        "            # We set NA so that csv parsers do not fail for this last epoch.\n",
        "            logs = dict([(k, logs[k]) if k in logs else (k, 'NA') for k in self.keys])\n",
        "\n",
        "        if not self.writer:\n",
        "            class CustomDialect(csv.excel):\n",
        "                delimiter = self.sep\n",
        "\n",
        "            fieldnames = ['epoch'] + self.keys\n",
        "\n",
        "            self.writer = csv.DictWriter(\n",
        "                self.csv_file,\n",
        "                fieldnames=fieldnames,\n",
        "                dialect=CustomDialect)\n",
        "            if self.append_header:\n",
        "                self.writer.writeheader()\n",
        "\n",
        "        row_dict = collections.OrderedDict({'epoch': epoch})\n",
        "        row_dict.update((key, handle_value(logs[key])) for key in self.keys)\n",
        "        self.writer.writerow(row_dict)\n",
        "        self.csv_file.flush()\n",
        "\n",
        "\n",
        "import os\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
        "# from callbacks.csv_callback import MyCSVLogger\n",
        "\n",
        "\n",
        "def create_callbacks(model_name, result_folder, other_callback=None, checkpoint=True, early_stop=True, metrics='accuracy'):\n",
        "    \"\"\"Creates callbacks for model training\n",
        "\n",
        "    :param model_name: model name\n",
        "    :param result_folder: folder to write to\n",
        "    :param other_callback: other evaluation callbacks\n",
        "    :param checkpoint: flag to use checkpoint or not\n",
        "    :param early_stop: flag to use early_stop or not\n",
        "    :param metrics: evaluation metrics for writing to checkpoint file\n",
        "    :return: callbacks\n",
        "    \"\"\"\n",
        "\n",
        "    callbacks = []\n",
        "    if other_callback is not None:\n",
        "        callbacks.append(other_callback)\n",
        "    csv_log_file = os.path.join(result_folder, model_name + '.log')\n",
        "    csv_logger = MyCSVLogger(csv_log_file, model_name, append=True, separator=';')\n",
        "    callbacks.append(csv_logger)\n",
        "    if early_stop:\n",
        "        callbacks.append(EarlyStopping(monitor='plcc', min_delta=0.001, patience=40, mode='max'))\n",
        "    if checkpoint:\n",
        "        if metrics == None:\n",
        "            mcp_file = os.path.join(result_folder, '{epoch:01d}_{loss:.4f}_{val_loss:.4f}.h5')\n",
        "        else:\n",
        "            if metrics == 'accuracy':\n",
        "                mcp_file = os.path.join(result_folder, '{epoch:01d}_{loss:.4f}_{accuracy:.4f}_{val_loss:.4f}_{val_accuracy:.4f}.h5')\n",
        "            elif metrics == 'mae':\n",
        "                mcp_file = os.path.join(result_folder, '{epoch:01d}_{loss:.4f}_{mae:.4f}_{val_loss:.4f}_{val_mae:.4f}.h5')\n",
        "            elif metrics == 'categorical_crossentropy':\n",
        "                mcp_file = os.path.join(result_folder, '{epoch:01d}_{loss:.4f}_{categorical_crossentropy:.4f}_{val_loss:.4f}_{val_categorical_crossentropy:.4f}.h5')\n",
        "            elif metrics == 'distribution_loss':\n",
        "                mcp_file = os.path.join(result_folder, '{epoch:01d}_{loss:.4f}_{distribution_loss:.4f}_{val_loss:.4f}_{val_distribution_loss:.4f}.h5')\n",
        "            else:\n",
        "                mcp_file = os.path.join(result_folder, '{epoch:01d}_{loss:.4f}_{val_loss:.4f}.h5')\n",
        "        mcp = ModelCheckpoint(mcp_file, save_best_only=True, save_weights_only=True, monitor='plcc', verbose=1, mode='max')\n",
        "        callbacks.append(mcp)\n",
        "\n",
        "    # tensorboard_callback = TensorBoard(log_dir=result_folder, histogram_freq=1)\n",
        "    # callbacks.append(tensorboard_callback)\n",
        "\n",
        "    return callbacks"
      ],
      "metadata": {
        "id": "knsVOzq6FdzY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Scores"
      ],
      "metadata": {
        "id": "7aI5jKTyGU41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This script contains several methods to process images and image groups\n",
        "\"\"\"\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from scipy.ndimage import sobel\n",
        "import shutil\n",
        "import glob\n",
        "import scipy.stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def si_image(image):\n",
        "    \"\"\"\n",
        "    SI of image based on the ITU-R Recommendation\n",
        "    :param image: image array\n",
        "    :return: SI\n",
        "    \"\"\"\n",
        "    # return np.mean(sobel(image))\n",
        "    return np.std(sobel(image))\n",
        "\n",
        "\n",
        "def get_scores(folders, image_scores):\n",
        "    \"\"\"\n",
        "    Get the image scores in folders\n",
        "    :param folders: data folders\n",
        "    :param image_scores: a dictionary of images and their MOS scores\n",
        "    :return: score list in the data folders\n",
        "    \"\"\"\n",
        "    scores = []\n",
        "    for folder in folders:\n",
        "        files = os.listdir(folder)\n",
        "        for file in files:\n",
        "            file_name = file.lower()\n",
        "            if file_name.endswith(('.jpg', '.bmp')):\n",
        "                score = image_scores[file_name]\n",
        "                scores.append(score)\n",
        "    return scores\n",
        "\n",
        "\n",
        "def get_image_means(train_folders):\n",
        "    \"\"\"\n",
        "    Get R,G,B means of images in the train folders\n",
        "    :param train_folders:\n",
        "    :return: R,G,B means\n",
        "    \"\"\"\n",
        "    # train_folders = [r'.\\image_quality_koniq10k\\train\\koniq_normal',\n",
        "    #                  r'.\\image_quality_koniq10k\\train\\koniq_small',\n",
        "    #                  r'.\\image_quality_koniq10k\\train\\live']\n",
        "    mean_R = 0\n",
        "    mean_G = 0\n",
        "    mean_B = 0\n",
        "    std_R = 0\n",
        "    std_G = 0\n",
        "    std_B = 0\n",
        "    num = 0\n",
        "    for folder in train_folders:\n",
        "        files = os.listdir(folder)\n",
        "        for file in files:\n",
        "            file_name = file.lower()\n",
        "            if file_name.endswith(('.jpg', '.bmp')):\n",
        "                image_file = os.path.join(folder, file)\n",
        "                image = np.asarray(Image.open(image_file), dtype=np.float32)\n",
        "                mean_R += np.mean(image[:, :, 0])\n",
        "                mean_G += np.mean(image[:, :, 1])\n",
        "                mean_B += np.mean(image[:, :, 2])\n",
        "                std_R += np.std(image[:, :, 0])\n",
        "                std_G += np.std(image[:, :, 1])\n",
        "                std_B += np.std(image[:, :, 2])\n",
        "                num += 1\n",
        "    mean_R /= num\n",
        "    mean_G /= num\n",
        "    mean_B /= num\n",
        "    std_R /= num\n",
        "    std_G /= num\n",
        "    std_B /= num\n",
        "    print('Mean-R: {}, mean-G: {}, mean-B:{}'.format(mean_R, mean_G, mean_B))\n",
        "    print('Std-R: {}, Std-G: {}, Std-B:{}'.format(std_R, std_G, std_B))\n",
        "\n",
        "\n",
        "def get_si(folders):\n",
        "    \"\"\"\n",
        "    Get SI values in data folders\n",
        "    :param folders: data folders\n",
        "    :return: SI list\n",
        "    \"\"\"\n",
        "    si = []\n",
        "    for folder in folders:\n",
        "        files = os.listdir(folder)\n",
        "        for file in files:\n",
        "            file_name = file.lower()\n",
        "            if file_name.endswith(('.jpg', '.bmp')):\n",
        "                image_file = os.path.join(folder, file)\n",
        "                image = np.asarray(Image.open(image_file), dtype=np.float32)\n",
        "                si.append(si_image(image))\n",
        "            print('{} done'.format(file))\n",
        "    return si\n",
        "\n",
        "\n",
        "def draw_train_val_si_hist():\n",
        "    \"\"\"\n",
        "    Draw the histogram of SI of train and validation sets\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    # train_folders = [r'.\\image_quality_koniq10k\\train\\koniq_normal',\n",
        "    #                  r'.\\image_quality_koniq10k\\train\\live']\n",
        "    # val_folders = [r'.\\image_quality_koniq10k\\val\\koniq_normal',\n",
        "    #                r'.\\image_quality_koniq10k\\val\\live']\n",
        "    train_folders = [r'.\\database\\train\\koniq_normal',\n",
        "                     r'.\\database\\train\\live']\n",
        "    val_folders = [r'.\\database\\val\\koniq_normal',\n",
        "                   r'.\\database\\val\\live']\n",
        "\n",
        "    train_si = get_si(train_folders)\n",
        "    val_si = get_si(val_folders)\n",
        "    np.save(r'.\\database\\train_si.npy', train_si)\n",
        "    np.save(r'.\\database\\val_si.npy', val_si)\n",
        "    max_si = np.max(train_si)\n",
        "    min_si = np.min(train_si)\n",
        "\n",
        "    plt.figure()\n",
        "    bins = np.linspace(min_si, max_si, 100)\n",
        "    # bins = 100\n",
        "    plt.hist(train_si, bins=bins, alpha=0.5, rwidth=0.95, color='skyblue', label='Train set')\n",
        "    plt.xlim(min_si, max_si)\n",
        "    plt.hist(val_si, bins=bins, alpha=1., rwidth=0.95, label='Validation set')\n",
        "    plt.legend(loc='upper right')\n",
        "    # plt.ylabel('Density')\n",
        "    plt.xlabel('SI', fontsize=14)\n",
        "    # plt.show()\n",
        "\n",
        "    # plt.subplot(211)\n",
        "    # plt.hist(train_si, density=True, bins=100)\n",
        "    # plt.ylabel('Density')\n",
        "    # plt.xlabel('Train SI')\n",
        "    #\n",
        "    # plt.subplot(212)\n",
        "    # plt.hist(val_si, density=True, bins=100)\n",
        "    # plt.ylabel('Density')\n",
        "    # plt.xlabel('Val SI')\n",
        "    # plt.show()\n",
        "\n",
        "\n",
        "def draw_train_val_mos_hist():\n",
        "    \"\"\"\n",
        "    Draw the histogram of MOS in the train and val sets\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    train_folders = [r'.\\database\\train\\koniq_normal',\n",
        "                     # r'.\\database\\train\\koniq_small',\n",
        "                     r'.\\database\\train\\live']\n",
        "    val_folders = [r'.\\database\\val\\koniq_normal',\n",
        "                   # r'.\\database\\val\\koniq_small',\n",
        "                   r'.\\database\\val\\live']\n",
        "\n",
        "    koniq_mos_file = r'.\\database\\koniq10k_images_scores.csv'\n",
        "    live_mos_file = r'.\\database\\live_wild\\live_mos.csv'\n",
        "    image_scores = get_image_scores(koniq_mos_file, live_mos_file)\n",
        "    train_scores = get_scores(train_folders, image_scores)\n",
        "    val_scores = get_scores(val_folders, image_scores)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.subplot(211)\n",
        "    bins = np.linspace(1, 5, 100)\n",
        "    plt.hist(train_scores, bins=bins, alpha=0.5, rwidth=0.95, color='skyblue', label='Training set')\n",
        "    plt.xlim(1, 5)\n",
        "    plt.hist(val_scores, bins=bins, alpha=1., rwidth=0.95, label='Testing set')\n",
        "    plt.legend(loc='upper left')\n",
        "    # plt.ylabel('Density')\n",
        "    plt.xlabel('MOS', fontsize=14)\n",
        "\n",
        "    train_si = np.load(r'.\\database\\train_si.npy')\n",
        "    val_si = np.load(r'.\\database\\val_si.npy')\n",
        "    max_si = np.max(train_si)\n",
        "    min_si = np.min(train_si)\n",
        "\n",
        "    plt.subplot(212)\n",
        "    bins = np.linspace(min_si, max_si, 100)\n",
        "    # bins = 100\n",
        "    plt.hist(train_si, bins=bins, alpha=0.5, rwidth=0.95, color='skyblue', label='Training set')\n",
        "    plt.xlim(min_si, max_si)\n",
        "    plt.hist(val_si, bins=bins, alpha=1., rwidth=0.95, label='Testing set')\n",
        "    plt.legend(loc='upper right')\n",
        "    # plt.ylabel('Density')\n",
        "    plt.xlabel('SI', fontsize=14)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def get_image_scores_from_two_file_formats(mos_file, file_format, mos_format, using_single_mos=True):\n",
        "    \"\"\"\n",
        "    Get single MOS or distribution of scores from mos files with two format: koniq and live\n",
        "    :param mos_file: mos file containing image path, distribution or std, and MOS\n",
        "    :param file_format: koniq or live\n",
        "    :param mos_format: MOS or Z-score\n",
        "    :param using_single_mos: single MOS or distribution\n",
        "    :return: dict {image_path: MOS or distribution}\n",
        "    \"\"\"\n",
        "    mos_scale = [1, 2, 3, 4, 5]\n",
        "    image_files = {}\n",
        "    with open(mos_file, 'r+') as f:\n",
        "        lines = f.readlines()\n",
        "        for line in lines:\n",
        "            content = line.split(',')\n",
        "            image_file = content[0].replace('\"', '').lower()\n",
        "\n",
        "            if using_single_mos:\n",
        "                score = float(content[-1]) if mos_format == 'mos' else float(content[1]) / 25. + 1\n",
        "            else:\n",
        "                if file_format == 'koniq':\n",
        "                    scores_softmax = np.array([float(score) for score in content[1 : 6]])\n",
        "                    score = [score_softmax / scores_softmax.sum() for score_softmax in scores_softmax]\n",
        "                else:\n",
        "                    std = float(content[-2]) if mos_format == 'mos' else float(content[-2]) / 25.\n",
        "                    mean = float(content[-1]) if mos_format == 'mos' else float(content[-1]) / 25. + 1\n",
        "                    score = get_distribution(mos_scale, mean, std)\n",
        "\n",
        "            image_files[image_file] = score\n",
        "    return image_files\n",
        "\n",
        "\n",
        "def get_image_scores(koniq_mos_file, live_mos_file, using_single_mos=True):\n",
        "    # image_scores_koniq = get_image_scores_from_two_file_formats(koniq_mos_file, 'koniq', 'mos', using_single_mos)\n",
        "    image_scores = get_image_scores_from_two_file_formats(koniq_mos_file, 'koniq', 'mos', using_single_mos)\n",
        "    # image_scores_live = get_image_scores_from_two_file_formats(live_mos_file, 'live', 'z-score', using_single_mos)\n",
        "    # return {**image_scores_koniq, **image_scores_live}\n",
        "    return {**image_scores}\n",
        "\n",
        "\n",
        "def get_image_score_from_groups(folders, image_scores):\n",
        "    \"\"\"\n",
        "    Get group lists of image files and scores\n",
        "    :param folders: image folders\n",
        "    :param image_scores: a dictionary of images and their MOS scores\n",
        "    :return: two lists\n",
        "                image_file_groups: a list containing image file groups, each group containing image files\n",
        "                score_groups: a list containing score groups, each group containing image scores\n",
        "    \"\"\"\n",
        "    image_file_groups = []\n",
        "    score_groups = []\n",
        "    for folder in folders:\n",
        "        files = os.listdir(folder)\n",
        "        image_file_group = []\n",
        "        score_group = []\n",
        "        for file in files:\n",
        "            file_name = file.lower()\n",
        "            if file_name in image_scores:\n",
        "                score = image_scores[file_name]\n",
        "                score_group.append(score)\n",
        "                image_file_group.append(os.path.join(folder, file))\n",
        "\n",
        "        image_file_groups.append(image_file_group)\n",
        "        score_groups.append(score_group)\n",
        "    return image_file_groups, score_groups\n",
        "\n",
        "\n",
        "def get_distribution(score_scale, mean, std, distribution_type='standard'):\n",
        "    \"\"\"\n",
        "    Calculate the distribution of scores from MOS and standard distribution, two types of distribution are supported:\n",
        "        standard Gaussian and Truncated Gaussian\n",
        "    :param score_scale: MOS scale, e.g., [1, 2, 3, 4, 5]\n",
        "    :param mean: MOS\n",
        "    :param std: standard deviation\n",
        "    :param distribution_type: distribution type (standard or truncated)\n",
        "    :return: Distribution of scores\n",
        "    \"\"\"\n",
        "    if distribution_type == 'standard':\n",
        "        distribution = scipy.stats.norm(loc=mean, scale=std)\n",
        "    else:\n",
        "        distribution = scipy.stats.truncnorm((score_scale[0] - mean) / std, (score_scale[-1] - mean) / std, loc=mean, scale=std)\n",
        "    score_distribution = []\n",
        "    for s in score_scale:\n",
        "        score_distribution.append(distribution.pdf(s))\n",
        "\n",
        "    return score_distribution\n",
        "\n",
        "\n",
        "def get_live_images():\n",
        "    image_folder = r'.\\database\\live_wild\\Images'\n",
        "    image_mos_file = r'.\\database\\live_wild\\live_mos.csv'\n",
        "    # image_si = []\n",
        "    # scores = []\n",
        "    image_files = {}\n",
        "    with open(image_mos_file, 'r+') as f:\n",
        "        lines = f.readlines()\n",
        "        for line in lines:\n",
        "            content = line.split(',')\n",
        "            image_file = os.path.join(image_folder, content[0])\n",
        "            # image_files.append(image_file)\n",
        "            # image = np.asarray(image_file, dtype=np.float32)\n",
        "            score = float(content[-1])\n",
        "            mos = (score / 25.) + 1\n",
        "            image_files[image_file] = mos\n",
        "            # scores.append(mos)\n",
        "            # image_si.append(si_image(image))\n",
        "    return image_files\n",
        "\n",
        "\n",
        "def split_train_val(ratio=0.5):\n",
        "    \"\"\"\n",
        "    Randomly split images in a database to training and testing sets in terms of SI and MOS\n",
        "    :param ratio: splitting ratio\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    target_train_folder = r'.\\database\\train\\live'\n",
        "    target_val_folder = r'.\\database\\val\\live'\n",
        "    # image_files = self.get_si_scores()\n",
        "    image_files = get_live_images()\n",
        "    mos_scale = [1, 2, 3, 4, 5]\n",
        "    image_groups = []\n",
        "    # train_image_files = []\n",
        "    # val_image_files = []\n",
        "    for s in range(len(mos_scale)-1):\n",
        "        images = []\n",
        "        for k, v in image_files.items():\n",
        "            if mos_scale[s] <= v < mos_scale[s + 1]:\n",
        "                images.append(k)\n",
        "        image_groups.append(images)\n",
        "\n",
        "    for image_group in image_groups:\n",
        "        image_si = {}\n",
        "        for image_file in image_group:\n",
        "            image = np.asarray(Image.open(image_file), dtype=np.float32)\n",
        "            si = si_image(image)\n",
        "            image_si[image_file] = si\n",
        "\n",
        "        sorted_si = {k : v for k, v in sorted(image_si.items(), key=lambda item: item[1])}\n",
        "        val_num = int(1.0 / (1 - ratio)) + 1\n",
        "        sorted_image_files = sorted_si.keys()\n",
        "        for i, sorted_image_file in enumerate(sorted_image_files):\n",
        "            basename = os.path.basename(sorted_image_file)\n",
        "            image = Image.open(sorted_image_file)\n",
        "            resized_image = image.resize(512, 512)\n",
        "            if i % val_num == 0:\n",
        "                resized_image.save(os.path.join(target_val_folder, basename))\n",
        "                # shutil.copy(sorted_image_file, os.path.join(target_val_folder, basename))\n",
        "                # val_image_files.append(sorted_image_file)\n",
        "            else:\n",
        "               resized_image.save(os.path.join(target_train_folder, basename))\n",
        "                # shutil.copy(sorted_image_file, os.path.join(target_train_folder, basename))\n",
        "                # train_image_files.append(sorted_image_file)\n",
        "\n",
        "\n",
        "def resize_koniq_images(image_folder):\n",
        "    \"\"\"\n",
        "    Halve size of images in the KonIQ-10k database\n",
        "    :param image_folder: image folder of KonIQ-10 database\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    target_folder = r'.\\database\\train\\koniq_small'\n",
        "    image_files = glob.glob(os.path.join(image_folder, '*.jpg'))\n",
        "    for image_file in image_files:\n",
        "        image = Image.open(image_file)\n",
        "        resized_image = image.resize((512, 384))\n",
        "        basename = os.path.basename(image_file)\n",
        "        resized_image.save(os.path.join(target_folder, basename))\n",
        "\n",
        "\n",
        "class GroupProvider:\n",
        "    def __init__(self, image_folder, image_mos_file):\n",
        "        self.image_folder = image_folder\n",
        "        self.image_mos_file = image_mos_file\n",
        "\n",
        "    def get_si_scores(self):\n",
        "        # image_si = []\n",
        "        # scores = []\n",
        "        image_files = {}\n",
        "        with open(self.image_mos_file, 'r+') as f:\n",
        "            lines = f.readlines()\n",
        "            for line in lines:\n",
        "                content = line.split(',')\n",
        "                image_file = os.path.join(self.image_folder, content[0].replace('\"', ''))\n",
        "                # image = np.asarray(Image.open(image_file), dtype=np.float32)\n",
        "                # si = si_image(image)\n",
        "                score = float(content[-3])\n",
        "                image_files[image_file] = score\n",
        "                # scores.append(score)\n",
        "                # image_si.append(si)\n",
        "        return image_files\n",
        "\n",
        "    def generate_images(self):\n",
        "        image_files, scores, image_files = self.get_si_scores()\n",
        "        train_image_files, test_image_files, train_scores, test_scores = train_test_split(image_files, scores,\n",
        "                                                                                          test_size=0.1,\n",
        "                                                                                          random_state=42)\n",
        "        return train_image_files, test_image_files, train_scores, test_scores\n",
        "\n",
        "    def get_live_images(self):\n",
        "        image_folder = r'.\\database\\live_wild\\Images'\n",
        "        image_mos_file = r'.\\database\\live_wild\\live_mos.csv'\n",
        "        # image_si = []\n",
        "        # scores = []\n",
        "        image_files = {}\n",
        "        with open(image_mos_file, 'r+') as f:\n",
        "            lines = f.readlines()\n",
        "            for line in lines:\n",
        "                content = line.split(',')\n",
        "                image_file = os.path.join(image_folder, content[0])\n",
        "                # image_files.append(image_file)\n",
        "                # image = np.asarray(image_file, dtype=np.float32)\n",
        "                score = float(content[1])\n",
        "                mos = (score / 25.) + 1\n",
        "                image_files[image_file] = mos\n",
        "                # scores.append(mos)\n",
        "                # image_si.append(si_image(image))\n",
        "        return image_files\n",
        "\n",
        "    def split_train_val(self, ratio=0.5):\n",
        "        target_train_folder = r'.\\database\\train\\live'\n",
        "        target_val_folder = r'.\\database\\val\\live'\n",
        "        # image_files = self.get_si_scores()\n",
        "        image_files = self.get_live_images()\n",
        "        mos_scale = [1, 2, 3, 4, 5]\n",
        "        image_groups = []\n",
        "        # train_image_files = []\n",
        "        # val_image_files = []\n",
        "        for s in range(len(mos_scale)-1):\n",
        "            images = []\n",
        "            for k, v in image_files.items():\n",
        "                if mos_scale[s] <= v < mos_scale[s + 1]:\n",
        "                    images.append(k)\n",
        "            image_groups.append(images)\n",
        "\n",
        "        for image_group in image_groups:\n",
        "            image_si = {}\n",
        "            for image_file in image_group:\n",
        "                image = np.asarray(Image.open(image_file), dtype=np.float32)\n",
        "                si = si_image(image)\n",
        "                image_si[image_file] = si\n",
        "\n",
        "            sorted_si = {k : v for k, v in sorted(image_si.items(), key=lambda item: item[1])}\n",
        "            val_num = int(1.0 / (1 - ratio)) + 1\n",
        "            sorted_image_files = sorted_si.keys()\n",
        "            for i, sorted_image_file in enumerate(sorted_image_files):\n",
        "                basename = os.path.basename(sorted_image_file)\n",
        "                image = Image.open(sorted_image_file)\n",
        "                resized_image = image.resize(512, 512)\n",
        "                if i % val_num == 0:\n",
        "                    resized_image.save(os.path.join(target_val_folder, basename))\n",
        "                    # shutil.copy(sorted_image_file, os.path.join(target_val_folder, basename))\n",
        "                    # val_image_files.append(sorted_image_file)\n",
        "                else:\n",
        "                   resized_image.save(os.path.join(target_train_folder, basename))\n",
        "                    # shutil.copy(sorted_image_file, os.path.join(target_train_folder, basename))\n",
        "                    # train_image_files.append(sorted_image_file)\n",
        "\n",
        "    def resize_koniq_images(self, image_folder):\n",
        "        target_folder = r'.\\database\\train\\koniq_small'\n",
        "        image_files = glob.glob(os.path.join(image_folder, '*.jpg'))\n",
        "        for image_file in image_files:\n",
        "            image = Image.open(image_file)\n",
        "            resized_image = image.resize((512, 384))\n",
        "            basename = os.path.basename(image_file)\n",
        "            resized_image.save(os.path.join(target_folder, basename))\n",
        "\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "    # image_folder = r'.\\database\\1024x768'\n",
        "    # image_mos_file = r'.\\database\\koniq10k_images_scores.csv'\n",
        "\n",
        "    # provider = GroupProvider(image_folder, image_mos_file)\n",
        "    # provider.split_train_val()\n",
        "    # print(1e-4/2)\n",
        "\n",
        "    # draw_train_val_si_hist()\n",
        "    # draw_train_val_mos_hist()\n",
        "    # get_distribution()\n",
        "\n",
        "    # get_image_means()\n",
        "\n",
        "    # v = [4,5]\n",
        "    # s = np.std(v)\n",
        "    #\n",
        "    # mean = 68.9221 / 25. + 1\n",
        "    # std = 21.2405 / 25.\n",
        "    # mos_scale = [1, 2, 3, 4, 5]\n",
        "    # score = get_distribution(mos_scale, mean, std)\n",
        "\n"
      ],
      "metadata": {
        "id": "IjsykYHnGUKV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "aVw9nh3JYmb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# from models.triq_model import create_triq_model\n",
        "# from callbacks.callbacks import create_callbacks\n",
        "# from misc.imageset_handler import get_image_scores, get_image_score_from_groups\n",
        "# from train.group_generator import GroupGenerator\n",
        "# from callbacks.evaluation_callback_generator import ModelEvaluationIQGenerator\n",
        "# from callbacks.warmup_cosine_decay_scheduler import WarmUpCosineDecayScheduler\n",
        "\n",
        "\n",
        "def identify_best_weights(result_folder, history, best_plcc):\n",
        "    pos = np.where(history['plcc'] == best_plcc)[0][0]\n",
        "\n",
        "    pos_loss = '{}_{:.4f}'.format(pos + 1, history['loss'][pos])\n",
        "    all_weights_files = glob.glob(os.path.join(result_folder, '*.h5'))\n",
        "    for all_weights_file in all_weights_files:\n",
        "        weight_file = os.path.basename(all_weights_file)\n",
        "        if weight_file.startswith(pos_loss):\n",
        "            best_weights_file = all_weights_file\n",
        "            return best_weights_file\n",
        "    return None\n",
        "\n",
        "\n",
        "def remove_non_best_weights(result_folder, best_weights_files):\n",
        "    all_weights_files = glob.glob(os.path.join(result_folder, '*.h5'))\n",
        "    for all_weights_file in all_weights_files:\n",
        "        if all_weights_file not in best_weights_files:\n",
        "            os.remove(all_weights_file)\n",
        "\n",
        "\n",
        "def train_main(args):\n",
        "    if args['multi_gpu'] == 0:\n",
        "        gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "        tf.config.experimental.set_visible_devices(gpus[args['gpu']], 'GPU')\n",
        "\n",
        "    result_folder = args['result_folder']\n",
        "    model_name = 'triq_conv2D_all'\n",
        "\n",
        "    # Define loss function according to prediction objective (score distribution or MOS)\n",
        "    if args['n_quality_levels'] > 1:\n",
        "        using_single_mos = False\n",
        "        loss = 'categorical_crossentropy'\n",
        "        metrics = None\n",
        "        model_name += '_distribution'\n",
        "    else:\n",
        "        using_single_mos = True\n",
        "        metrics = None\n",
        "        loss = 'mse'\n",
        "        model_name += '_mos'\n",
        "\n",
        "    if args['lr_base'] < 1e-4 / 2:\n",
        "        model_name += '_finetune'\n",
        "    if not args['image_aug']:\n",
        "        model_name += '_no_imageaug'\n",
        "\n",
        "    optimizer = Adam(args['lr_base'])\n",
        "\n",
        "    if args['multi_gpu'] > 0:\n",
        "        strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\n",
        "        print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
        "\n",
        "        with strategy.scope():\n",
        "            # Everything that creates variables should be under the strategy scope.\n",
        "            # In general this is only model construction & `compile()`.\n",
        "            model = create_triq_model(n_quality_levels=5,\n",
        "                                      input_shape=(None, None, 3),\n",
        "                                      backbone=args['backbone'],\n",
        "                                      maximum_position_encoding=193)\n",
        "\n",
        "            model.compile(loss=loss, optimizer=optimizer, metrics=[metrics])\n",
        "\n",
        "    else:\n",
        "        model = create_triq_model(n_quality_levels=5,\n",
        "                                  input_shape=(None, None, 3),\n",
        "                                  backbone=args['backbone'],\n",
        "                                  maximum_position_encoding=193)\n",
        "        model.compile(loss=loss, optimizer=optimizer, metrics=[metrics])\n",
        "\n",
        "    # model.summary()\n",
        "    print('Load ImageNet weights')\n",
        "    model.load_weights(args['weights'], by_name=True)\n",
        "\n",
        "    imagenet_pretrain = True\n",
        "\n",
        "    # Define train and validation data\n",
        "    image_scores = get_image_scores(args['koniq_mos_file'], args['live_mos_file'], using_single_mos=using_single_mos)\n",
        "    \"\"\"\n",
        "    train_image_file_groups, train_score_groups = get_image_score_from_groups(args['train_folders'], image_scores)\n",
        "    train_generator = GroupGenerator(train_image_file_groups,\n",
        "                                     train_score_groups,\n",
        "                                     batch_size=args['batch_size'],\n",
        "                                     image_aug=args['image_aug'],\n",
        "                                     imagenet_pretrain=imagenet_pretrain)\n",
        "    train_steps = train_generator.__len__()\n",
        "\n",
        "    if args['val_folders'] is not None:\n",
        "        test_image_file_groups, test_score_groups = get_image_score_from_groups(args['val_folders'], image_scores)\n",
        "        validation_generator = GroupGenerator(test_image_file_groups,\n",
        "                                              test_score_groups,\n",
        "                                              batch_size=args['batch_size'],\n",
        "                                              image_aug=False,\n",
        "                                              imagenet_pretrain=imagenet_pretrain)\n",
        "        validation_steps = validation_generator.__len__()\n",
        "\n",
        "        evaluation_callback = ModelEvaluationIQGenerator(validation_generator,\n",
        "                                                         using_single_mos,\n",
        "                                                         evaluation_generator=None)\n",
        "\n",
        "    else:\n",
        "        evaluation_callback = None\n",
        "        validation_generator = None\n",
        "        validation_steps = 0\n",
        "\"\"\"\n",
        "    result_folder = os.path.join(result_folder, model_name)\n",
        "    if not os.path.exists(result_folder):\n",
        "        os.makedirs(result_folder)\n",
        "\n",
        "    # Create callbacks including evaluation and learning rate scheduler\n",
        "    callbacks = create_callbacks(model_name,\n",
        "                                 result_folder,\n",
        "                                 evaluation_callback,\n",
        "                                 checkpoint=True,\n",
        "                                 early_stop=True,\n",
        "                                 metrics=metrics)\n",
        "\n",
        "    warmup_epochs = 10\n",
        "    if args['lr_schedule']:\n",
        "        total_train_steps = args['epochs'] * train_steps\n",
        "        warmup_steps = warmup_epochs * train_steps\n",
        "        warmup_lr = WarmUpCosineDecayScheduler(learning_rate_base=args['lr_base'],\n",
        "                                               total_steps=total_train_steps,\n",
        "                                               warmup_learning_rate=0.0,\n",
        "                                               warmup_steps=warmup_steps,\n",
        "                                               hold_base_rate_steps=30 * train_steps,\n",
        "                                               verbose=1)\n",
        "        callbacks.append(warmup_lr)\n",
        "\n",
        "\n",
        "    # Define optimizer and train\n",
        "\n",
        "    model_history = model.fit(x=train_generator,\n",
        "                              epochs=args['epochs'],\n",
        "                              steps_per_epoch=train_steps,\n",
        "                              validation_data=validation_generator,\n",
        "                              validation_steps=validation_steps,\n",
        "                              verbose=1,\n",
        "                              shuffle=False,\n",
        "                              callbacks=callbacks,\n",
        "                              initial_epoch=args['initial_epoch'],\n",
        "                              )\n",
        "\n",
        "    # model.save(os.path.join(result_folder, model_name + '.h5'))\n",
        "    # plot_history(model_history, result_folder, model_name)\n",
        "\n",
        "    best_weights_file = identify_best_weights(result_folder, model_history.history, callbacks[3].best)\n",
        "    remove_non_best_weights(result_folder, [best_weights_file])\n",
        "\n",
        "    # do fine-tuning\n",
        "    if args['do_finetune'] and best_weights_file:\n",
        "        print('Finetune...')\n",
        "        del (callbacks[-1])\n",
        "        model.load_weights(best_weights_file)\n",
        "        finetune_lr = 1e-6\n",
        "        if args['lr_schedule']:\n",
        "            warmup_lr_finetune = WarmUpCosineDecayScheduler(learning_rate_base=finetune_lr,\n",
        "                                                            total_steps=total_train_steps,\n",
        "                                                            warmup_learning_rate=0.0,\n",
        "                                                            warmup_steps=warmup_steps,\n",
        "                                                            hold_base_rate_steps=10 * train_steps,\n",
        "                                                            verbose=1)\n",
        "            callbacks.append(warmup_lr_finetune)\n",
        "        finetune_optimizer = Adam(finetune_lr)\n",
        "        model.compile(loss=loss, optimizer=finetune_optimizer, metrics=[metrics])\n",
        "\n",
        "        finetune_model_history = model.fit(x=train_generator,\n",
        "                                  epochs=args['epochs'],\n",
        "                                  steps_per_epoch=train_steps,\n",
        "                                  validation_data=validation_generator,\n",
        "                                  validation_steps=validation_steps,\n",
        "                                  verbose=1,\n",
        "                                  shuffle=False,\n",
        "                                  callbacks=callbacks,\n",
        "                                  initial_epoch=args['initial_epoch'],\n",
        "                                  )\n",
        "\n",
        "        best_weights_file_finetune = identify_best_weights(result_folder, finetune_model_history.history, callbacks[3].best)\n",
        "        remove_non_best_weights(result_folder, [best_weights_file, best_weights_file_finetune])\n",
        "\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "# def main():\n",
        "args = {}\n",
        "args['multi_gpu'] = 1\n",
        "args['gpu'] = 1\n",
        "\n",
        "args['result_folder'] = r'.\\database\\results_triq\\triq_conv2D_all'\n",
        "args['n_quality_levels'] = 5\n",
        "\n",
        "args['backbone'] = 'resnet50'\n",
        "\n",
        "args['train_folders'] = [\n",
        "        r'.\\database\\train\\koniq_normal',\n",
        "        r'.\\database\\train\\koniq_small',\n",
        "        r'.\\database\\train\\live']\n",
        "args['val_folders'] = [\n",
        "        r'.\\database\\val\\koniq_normal',\n",
        "        r'.\\database\\val\\koniq_small',\n",
        "        r'.\\database\\val\\live']\n",
        "# args['koniq_mos_file'] = r'.\\database\\koniq10k_images_scores.csv'\n",
        "args['live_mos_file'] = r'.\\database\\live_wild\\live_mos.csv'\n",
        "\n",
        "args['initial_epoch'] = 0\n",
        "\n",
        "args['lr_base'] = 1e-4/2\n",
        "args['lr_schedule'] = True\n",
        "args['batch_size'] = 8\n",
        "args['epochs'] = 120\n",
        "\n",
        "args['image_aug'] = True\n",
        "    # args['weights'] = r'.\\pretrained_weights\\vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "# args['weights'] = r'.\\pretrained_weights\\resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "args['weights'] = r'./drive/MyDrive/iqa/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "args['do_finetune'] = True\n",
        "\n",
        "train_main(args)"
      ],
      "metadata": {
        "id": "eGo0h7lqYF4T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "bf0692da-268d-452c-ace5-86130cd39cbb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of devices: 1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-36d09f1d434d>\u001b[0m in \u001b[0;36m<cell line: 230>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'do_finetune'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m \u001b[0mtrain_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-36d09f1d434d>\u001b[0m in \u001b[0;36mtrain_main\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Everything that creates variables should be under the strategy scope.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# In general this is only model construction & `compile()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             model = create_triq_model(n_quality_levels=5,\n\u001b[0m\u001b[1;32m     70\u001b[0m                                       \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                                       \u001b[0mbackbone\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'backbone'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-5f4666e0cefe>\u001b[0m in \u001b[0;36mcreate_triq_model\u001b[0;34m(n_quality_levels, input_shape, backbone, transformer_params, maximum_position_encoding, vis)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbackbone\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'resnet50'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         backbone_model = ResNet50(inputs,\n\u001b[0m\u001b[1;32m     30\u001b[0m                                   return_feature_maps=False, return_last_map=True)\n\u001b[1;32m     31\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mbackbone\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'vgg16'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/applications/resnet.py\u001b[0m in \u001b[0;36mResNet50\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstack1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"conv5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m     return ResNet(\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0mstack_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/applications/resnet.py\u001b[0m in \u001b[0;36mResNet\u001b[0;34m(stack_fn, preact, use_bias, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVersionAwareLayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unknown argument(s): {kwargs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"imagenet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         raise ValueError(\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown argument(s): {'return_feature_maps': False, 'return_last_map': True}"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train & test data"
      ],
      "metadata": {
        "id": "CK22KYQHe3op"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Import necessary libraries\n",
        "import torch\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "def load_images_from_folder(folder_path):\n",
        "    transform = transforms.Compose([\n",
        "      transforms.PILToTensor()\n",
        "  ])\n",
        "    images = []\n",
        "    image_path = []\n",
        "    labels = []\n",
        "    i=0\n",
        "    print(folder_path)\n",
        "    for filename in os.listdir(folder_path):\n",
        "        # if i== 100:\n",
        "        #   break\n",
        "        label = filename.split('.')[0]  # Assuming the filename is in the format \"label.xxx.jpg/png\"\n",
        "\n",
        "        path = os.path.join(folder_path, filename)\n",
        "        img = cv2.imread(path)\n",
        "        # if path == '/content/dataset/ChallengeDB_release/Images/trainingImages' or path == '/content/dataset/ChallengeDB_release/Images/.DS_Store':\n",
        "        #   continue\n",
        "        # img = Image.open(path).convert('RGB')\n",
        "        # img = transform(img)\n",
        "        if img is not None:\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB format\n",
        "            # print(type(img.tolist)))\n",
        "            # torch.cat(images, out=img)\n",
        "            # torch.cat(label, out=img)\n",
        "            images.append(img)\n",
        "            image_path.append(path)\n",
        "            labels.append(labels_data[int(label)-1])\n",
        "        i+=1\n",
        "    return images, labels, image_path\n",
        "\n",
        "# Path to the folder containing your images\n",
        "folder_path = '/content/dataset/ChallengeDB_release/Images'\n",
        "\n",
        "images, labels, image_path = load_images_from_folder(folder_path)\n",
        "\n",
        "# You might need to preprocess your images here (resize, normalize, etc.) before using them to train your CNN model\n",
        "\n",
        "# Convert the lists to numpy arrays\n",
        "images = np.asarray(images)\n",
        "# labels = np.asarray(labels)\n",
        "# print(images)\n",
        "# images = torch.FloatTensor(images)\n",
        "# labels = torch.tensor(labels)\n",
        "# images = torch.cat(images)\n",
        "# labels = torch.cat(labels)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(image_path, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Now, you can use train_images, train_labels, test_images, and test_labels to train your CNN model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9OTnyl3D0HW",
        "outputId": "509bc718-0951-4d68-813d-80bb7b6f6807"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dataset/ChallengeDB_release/Images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-259cf6c71179>:52: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  images = np.asarray(images)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = [str(int(i/20)) for i in train_labels]\n",
        "test_labels = [str(int(i/20)) for i in test_labels]"
      ],
      "metadata": {
        "id": "h7kOveCGgHSi"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define parameters for ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,  # rescale pixel values between 0 and 1\n",
        "    # rotation_range=20,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    # width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
        "    # height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
        "    # shear_range=0.2,  # shear intensity (angle in counter-clockwise direction in degrees)\n",
        "    # zoom_range=0.2,  # randomly zooming inside pictures\n",
        "    # horizontal_flip=False,  # randomly flip images horizontally\n",
        "    # fill_mode='nearest'  # strategy used for filling in newly created pixels\n",
        ")\n",
        "train_dataframe = pd.DataFrame({'filename': train_images, 'class': train_labels})\n",
        "# Provide the directory where your images are stored\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_generator = datagen.flow_from_dataframe(\n",
        "    dataframe = train_dataframe ,  # path to the training data folder\n",
        "    target_size=(500, 500),  # resizing images to a fixed size\n",
        "    batch_size=8,\n",
        "    class_mode='categorical',\n",
        "    classes=train_dataframe['class'].unique().tolist()# binary labels (if you have more classes, use 'categorical')\n",
        ")\n",
        "\n",
        "\n",
        "test_dataframe = pd.DataFrame({'filename':test_images,'class': test_labels})\n",
        "test_generator = datagen.flow_from_dataframe(\n",
        "    dataframe = test_dataframe,  # path to the training data folder\n",
        "    target_size=(500, 500),  # resizing images to a fixed size\n",
        "    batch_size=8,\n",
        "    class_mode='categorical',\n",
        "    classes=train_dataframe['class'].unique().tolist()# binary labels (if you have more classes, use 'categorical')\n",
        ")\n",
        "\n",
        "# Use the generator in model training\n",
        "# model.fit_generator(\n",
        "#     train_generator,\n",
        "#     steps_per_epoch=2000 // 32,  # total_training_samples // batch_size\n",
        "#     epochs=50\n",
        "# )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKM82DwPlLjT",
        "outputId": "892b57c5-3aa2-487b-97de-30bc3ef6f690"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 929 validated image filenames belonging to 5 classes.\n",
            "Found 233 validated image filenames belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "model = create_triq_model(n_quality_levels=5,\n",
        "                                  input_shape=(500, 500, 3),\n",
        "                                  backbone='resnet50',\n",
        "                                  maximum_position_encoding=193)\n",
        "loss = 'categorical_crossentropy'\n",
        "metrics = None\n",
        "optimizer = Adam(1e-3/2)\n",
        "model.compile(loss=loss, optimizer=optimizer, metrics=[metrics])"
      ],
      "metadata": {
        "id": "kucs90cfNbNZ"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ncCMd9Te8JAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_steps = train_generator.__len__()\n",
        "test_steps = test_generator.__len__()"
      ],
      "metadata": {
        "id": "7nmf5L_P9LVF"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for data_batch, labels_batch in train_generator:\n",
        "    print('Data batch shape:', data_batch.shape)\n",
        "    print(labels_batch) # Shape of the batch of images\n",
        "    print('Labels batch shape:', labels_batch.shape)  # Shape of the batch of labels\n",
        "    break\n",
        "for data_batch, labels_batch in test_generator:\n",
        "    print('Data batch shape:', data_batch.shape)\n",
        "    print(labels_batch)  # Shape of the batch of images\n",
        "    print('Labels batch shape:', labels_batch.shape)  # Shape of the batch of labels\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nl5LRDZz4wx0",
        "outputId": "29852bca-119e-4c55-df87-a59c36d8dc19"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data batch shape: (8, 500, 500, 3)\n",
            "[[0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0.]]\n",
            "Labels batch shape: (8, 5)\n",
            "Data batch shape: (8, 500, 500, 3)\n",
            "[[1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]]\n",
            "Labels batch shape: (8, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_history = model.fit(train_generator,\n",
        "                              epochs=10,\n",
        "                              steps_per_epoch=train_steps,\n",
        "                              validation_data=test_generator,\n",
        "                              validation_steps=test_steps,\n",
        "                              verbose=1,\n",
        "                              batch_size=8\n",
        "                              )"
      ],
      "metadata": {
        "id": "EET7wtzsOSfR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17f94f0a-c304-489c-8400-e1de31617e2b"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "117/117 [==============================] - 127s 483ms/step - loss: 1.4557 - val_loss: 1.4541\n",
            "Epoch 2/10\n",
            "117/117 [==============================] - 56s 481ms/step - loss: 1.4104 - val_loss: 1.4204\n",
            "Epoch 3/10\n",
            "117/117 [==============================] - 56s 479ms/step - loss: 1.4035 - val_loss: 1.4200\n",
            "Epoch 4/10\n",
            "117/117 [==============================] - 56s 482ms/step - loss: 1.4180 - val_loss: 1.4383\n",
            "Epoch 5/10\n",
            "117/117 [==============================] - 56s 478ms/step - loss: 1.4047 - val_loss: 1.4183\n",
            "Epoch 6/10\n",
            "117/117 [==============================] - 56s 482ms/step - loss: 1.3932 - val_loss: 1.4166\n",
            "Epoch 7/10\n",
            "117/117 [==============================] - 57s 484ms/step - loss: 1.3954 - val_loss: 1.4253\n",
            "Epoch 8/10\n",
            "117/117 [==============================] - 57s 486ms/step - loss: 1.3960 - val_loss: 1.4213\n",
            "Epoch 9/10\n",
            "117/117 [==============================] - 57s 488ms/step - loss: 1.4009 - val_loss: 1.4318\n",
            "Epoch 10/10\n",
            "117/117 [==============================] - 56s 480ms/step - loss: 1.3994 - val_loss: 1.4292\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numba import cuda\n",
        "device = cuda.get_current_device()\n",
        "device.reset()"
      ],
      "metadata": {
        "id": "KbxhwNkddaTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.predict(test_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTvPXlGGF3D2",
        "outputId": "43c27ab5-04c7-453d-fa21-252e4eb82cc1"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30/30 [==============================] - 7s 150ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_test_classes = []\n",
        "for sample in results:\n",
        "  quality = 0\n",
        "  for i in range(5):\n",
        "    quality += sample[i]*i\n",
        "  predicted_test_classes.append(quality)"
      ],
      "metadata": {
        "id": "DTNIjCKAGRfu"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results[10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ex0ieYs_O0PU",
        "outputId": "6637ed53-0125-4e4a-e582-8b787539432f"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.45605758, 0.06827413, 0.27128553, 0.12835717, 0.07602566],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_test_classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0AqzLQjHN88",
        "outputId": "ba8bf556-252e-4c2d-d303-456ab900f450"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.2722263187170029,\n",
              " 1.2783728241920471,\n",
              " 1.2701248154044151,\n",
              " 1.2871485650539398,\n",
              " 1.2783337235450745,\n",
              " 1.2708377316594124,\n",
              " 1.2590095326304436,\n",
              " 1.269657738506794,\n",
              " 1.2779415175318718,\n",
              " 1.2732749581336975,\n",
              " 1.3000193387269974,\n",
              " 1.3002692386507988,\n",
              " 1.2646305486559868,\n",
              " 1.302994281053543,\n",
              " 1.299253299832344,\n",
              " 1.261731095612049,\n",
              " 1.2642550617456436,\n",
              " 1.2804260849952698,\n",
              " 1.2707082107663155,\n",
              " 1.3041929826140404,\n",
              " 1.301278680562973,\n",
              " 1.2737338170409203,\n",
              " 1.2714650928974152,\n",
              " 1.2783905863761902,\n",
              " 1.2717852219939232,\n",
              " 1.2639565020799637,\n",
              " 1.270854502916336,\n",
              " 1.2998098954558372,\n",
              " 1.2730018571019173,\n",
              " 1.2678489536046982,\n",
              " 1.3012461438775063,\n",
              " 1.3031225427985191,\n",
              " 1.3009610623121262,\n",
              " 1.2756898924708366,\n",
              " 1.2740958705544472,\n",
              " 1.2648754939436913,\n",
              " 1.3016283214092255,\n",
              " 1.2943001314997673,\n",
              " 1.289016880095005,\n",
              " 1.2717735469341278,\n",
              " 1.2743413746356964,\n",
              " 1.280335620045662,\n",
              " 1.2720211446285248,\n",
              " 1.30580023676157,\n",
              " 1.2690058574080467,\n",
              " 1.2664222568273544,\n",
              " 1.273209162056446,\n",
              " 1.3011225834488869,\n",
              " 1.2670867592096329,\n",
              " 1.271631971001625,\n",
              " 1.2771576344966888,\n",
              " 1.2778190448880196,\n",
              " 1.3002365306019783,\n",
              " 1.2769973874092102,\n",
              " 1.2729796841740608,\n",
              " 1.3020746633410454,\n",
              " 1.3029200211167336,\n",
              " 1.300830826163292,\n",
              " 1.2767100855708122,\n",
              " 1.281154990196228,\n",
              " 1.2723977789282799,\n",
              " 1.271460898220539,\n",
              " 1.2721507847309113,\n",
              " 1.3020152375102043,\n",
              " 1.3081797137856483,\n",
              " 1.2834115251898766,\n",
              " 1.2705787047743797,\n",
              " 1.2510630786418915,\n",
              " 1.2733687087893486,\n",
              " 1.2734816819429398,\n",
              " 1.3094663843512535,\n",
              " 1.2740479111671448,\n",
              " 1.301739476621151,\n",
              " 1.2642292901873589,\n",
              " 1.300938032567501,\n",
              " 1.2692737430334091,\n",
              " 1.3009859919548035,\n",
              " 1.271926835179329,\n",
              " 1.264269433915615,\n",
              " 1.3015485554933548,\n",
              " 1.267524093389511,\n",
              " 1.3066758811473846,\n",
              " 1.2680737376213074,\n",
              " 1.2586457058787346,\n",
              " 1.3056667372584343,\n",
              " 1.3009319454431534,\n",
              " 1.2734927907586098,\n",
              " 1.2585778087377548,\n",
              " 1.2917331904172897,\n",
              " 1.2705715149641037,\n",
              " 1.3031211346387863,\n",
              " 1.3017438650131226,\n",
              " 1.2625996246933937,\n",
              " 1.2766161561012268,\n",
              " 1.2759197428822517,\n",
              " 1.302525632083416,\n",
              " 1.2860736548900604,\n",
              " 1.2661760300397873,\n",
              " 1.2759094685316086,\n",
              " 1.262677639722824,\n",
              " 1.2977821677923203,\n",
              " 1.3046740591526031,\n",
              " 1.2994361147284508,\n",
              " 1.3003157749772072,\n",
              " 1.2735117003321648,\n",
              " 1.2950198873877525,\n",
              " 1.3028313368558884,\n",
              " 1.2545960322022438,\n",
              " 1.2686707898974419,\n",
              " 1.2704569697380066,\n",
              " 1.2995272502303123,\n",
              " 1.2643972337245941,\n",
              " 1.300884686410427,\n",
              " 1.2807080671191216,\n",
              " 1.305383451282978,\n",
              " 1.2821528315544128,\n",
              " 1.2638412117958069,\n",
              " 1.2773522436618805,\n",
              " 1.3058220073580742,\n",
              " 1.2786251083016396,\n",
              " 1.276619777083397,\n",
              " 1.3018101453781128,\n",
              " 1.269613802433014,\n",
              " 1.2731919139623642,\n",
              " 1.270607016980648,\n",
              " 1.2680469527840614,\n",
              " 1.2693841606378555,\n",
              " 1.277735374867916,\n",
              " 1.2764722853899002,\n",
              " 1.2789907902479172,\n",
              " 1.2736004143953323,\n",
              " 1.3013275861740112,\n",
              " 1.2596026733517647,\n",
              " 1.3010789901018143,\n",
              " 1.2657648622989655,\n",
              " 1.2812285497784615,\n",
              " 1.2735392898321152,\n",
              " 1.2790522277355194,\n",
              " 1.2741606459021568,\n",
              " 1.2741722017526627,\n",
              " 1.2572566792368889,\n",
              " 1.3021358475089073,\n",
              " 1.270402267575264,\n",
              " 1.2715032398700714,\n",
              " 1.272483691573143,\n",
              " 1.2768224701285362,\n",
              " 1.3057401478290558,\n",
              " 1.2833771333098412,\n",
              " 1.2641041278839111,\n",
              " 1.2937779948115349,\n",
              " 1.2751743346452713,\n",
              " 1.2683904245495796,\n",
              " 1.3027345910668373,\n",
              " 1.2685677260160446,\n",
              " 1.275919958949089,\n",
              " 1.2797440886497498,\n",
              " 1.301118828356266,\n",
              " 1.2642204761505127,\n",
              " 1.2735519707202911,\n",
              " 1.2997483760118484,\n",
              " 1.2603181079030037,\n",
              " 1.2826274186372757,\n",
              " 1.267966590821743,\n",
              " 1.3013572096824646,\n",
              " 1.2806473970413208,\n",
              " 1.2791153863072395,\n",
              " 1.2781760692596436,\n",
              " 1.3043200001120567,\n",
              " 1.2604388892650604,\n",
              " 1.270088143646717,\n",
              " 1.305499091744423,\n",
              " 1.3089916408061981,\n",
              " 1.2740214169025421,\n",
              " 1.2768576815724373,\n",
              " 1.3018701151013374,\n",
              " 1.2713253200054169,\n",
              " 1.2651933804154396,\n",
              " 1.3016616180539131,\n",
              " 1.2697146758437157,\n",
              " 1.2716038599610329,\n",
              " 1.2661033943295479,\n",
              " 1.2730341777205467,\n",
              " 1.267819419503212,\n",
              " 1.2704747319221497,\n",
              " 1.3082272335886955,\n",
              " 1.3007575049996376,\n",
              " 1.2703612744808197,\n",
              " 1.2755557224154472,\n",
              " 1.3005883991718292,\n",
              " 1.2692065387964249,\n",
              " 1.3016968220472336,\n",
              " 1.2734173461794853,\n",
              " 1.3000306859612465,\n",
              " 1.2988113760948181,\n",
              " 1.2728844061493874,\n",
              " 1.2842810153961182,\n",
              " 1.27080999314785,\n",
              " 1.2602841258049011,\n",
              " 1.2686219364404678,\n",
              " 1.2996762245893478,\n",
              " 1.273355595767498,\n",
              " 1.2730850279331207,\n",
              " 1.278057873249054,\n",
              " 1.2723324671387672,\n",
              " 1.3018618524074554,\n",
              " 1.3005722910165787,\n",
              " 1.277476616203785,\n",
              " 1.3011354207992554,\n",
              " 1.2782696932554245,\n",
              " 1.2747105807065964,\n",
              " 1.2630417495965958,\n",
              " 1.272348240017891,\n",
              " 1.2724158242344856,\n",
              " 1.2781760692596436,\n",
              " 1.3044427633285522,\n",
              " 1.2806247994303703,\n",
              " 1.2795497849583626,\n",
              " 1.3074083998799324,\n",
              " 1.300263062119484,\n",
              " 1.3006335869431496,\n",
              " 1.2747774943709373,\n",
              " 1.272167406976223,\n",
              " 1.2641297429800034,\n",
              " 1.274181567132473,\n",
              " 1.2780697792768478,\n",
              " 1.3021851927042007,\n",
              " 1.262169636785984,\n",
              " 1.3014419451355934,\n",
              " 1.2750685662031174,\n",
              " 1.280326947569847,\n",
              " 1.2722787484526634,\n",
              " 1.2875469028949738,\n",
              " 1.3034625053405762]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    }
  ]
}